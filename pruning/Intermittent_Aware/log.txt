
==> Setting params:
batch_size : 128
test_batch_size : 128
epochs : 60
lr_epochs : 15
lr : 0.1
momentum : 0.9
weight_decay : 0.0001
no_cuda : False
seed : 1
log_interval : 100
arch : LeNet_5
pretrained : saved_models/LeNet_5.origin.pth.tar
evaluate : False
retrain : False
prune : intermittent
prune_target : None
stage : 0
group : [1, 1, 1, 5]
penalty : 0.0
pruning_ratio : 0.0
threshold : 0.0
with_sen : False
cuda : False
====================

LeNet_5(
  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv1): ReLU(inplace=True)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv2): ReLU(inplace=True)
  (pool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (ip1): Linear(in_features=256, out_features=256, bias=True)
  (relu_ip1): ReLU(inplace=True)
  (ip2): Linear(in_features=256, out_features=10, bias=True)
)
==> Start pruning ...
pruning_ratios: [0.35, 0.4, 0.3, 0.25]
------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 1 [0/60000 (0%)]	Loss: 0.012534
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.013859
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.015487
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.004816
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.001481
==> Saving model ...

Test set: Average loss: 0.0341, Accuracy: 9904/10000 (99.04%)
Best Accuracy: 99.04%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 2 [0/60000 (0%)]	Loss: 0.030037
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.000386
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.022411
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.029166
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.004563
==> Saving model ...

Test set: Average loss: 0.0370, Accuracy: 9888/10000 (98.88%)
Best Accuracy: 98.88%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 3 [0/60000 (0%)]	Loss: 0.053990
Train Epoch: 3 [12800/60000 (21%)]	Loss: 0.002022
Train Epoch: 3 [25600/60000 (43%)]	Loss: 0.034171
Train Epoch: 3 [38400/60000 (64%)]	Loss: 0.024895
Train Epoch: 3 [51200/60000 (85%)]	Loss: 0.000824
==> Saving model ...

Test set: Average loss: 0.0389, Accuracy: 9879/10000 (98.79%)
Best Accuracy: 98.79%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 4 [0/60000 (0%)]	Loss: 0.020051
Train Epoch: 4 [12800/60000 (21%)]	Loss: 0.002582
Train Epoch: 4 [25600/60000 (43%)]	Loss: 0.002249
Train Epoch: 4 [38400/60000 (64%)]	Loss: 0.010205
Train Epoch: 4 [51200/60000 (85%)]	Loss: 0.025165
==> Saving model ...

Test set: Average loss: 0.0463, Accuracy: 9869/10000 (98.69%)
Best Accuracy: 98.69%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 5 [0/60000 (0%)]	Loss: 0.012054
Train Epoch: 5 [12800/60000 (21%)]	Loss: 0.025962
Train Epoch: 5 [25600/60000 (43%)]	Loss: 0.000907
Train Epoch: 5 [38400/60000 (64%)]	Loss: 0.016379
Train Epoch: 5 [51200/60000 (85%)]	Loss: 0.021210
==> Saving model ...

Test set: Average loss: 0.0345, Accuracy: 9911/10000 (99.11%)
Best Accuracy: 99.11%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 6 [0/60000 (0%)]	Loss: 0.003433
Train Epoch: 6 [12800/60000 (21%)]	Loss: 0.009011
Train Epoch: 6 [25600/60000 (43%)]	Loss: 0.025243
Train Epoch: 6 [38400/60000 (64%)]	Loss: 0.009590
Train Epoch: 6 [51200/60000 (85%)]	Loss: 0.015222
==> Saving model ...

Test set: Average loss: 0.0340, Accuracy: 9901/10000 (99.01%)
Best Accuracy: 99.01%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 7 [0/60000 (0%)]	Loss: 0.012935
Train Epoch: 7 [12800/60000 (21%)]	Loss: 0.003389
Train Epoch: 7 [25600/60000 (43%)]	Loss: 0.020271
Train Epoch: 7 [38400/60000 (64%)]	Loss: 0.005391
Train Epoch: 7 [51200/60000 (85%)]	Loss: 0.014984
==> Saving model ...

Test set: Average loss: 0.0461, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 8 [0/60000 (0%)]	Loss: 0.006059
Train Epoch: 8 [12800/60000 (21%)]	Loss: 0.001689
Train Epoch: 8 [25600/60000 (43%)]	Loss: 0.002885
Train Epoch: 8 [38400/60000 (64%)]	Loss: 0.001576
Train Epoch: 8 [51200/60000 (85%)]	Loss: 0.003020
==> Saving model ...

Test set: Average loss: 0.0457, Accuracy: 9884/10000 (98.84%)
Best Accuracy: 98.84%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 9 [0/60000 (0%)]	Loss: 0.003360
Train Epoch: 9 [12800/60000 (21%)]	Loss: 0.008640
Train Epoch: 9 [25600/60000 (43%)]	Loss: 0.003590
Train Epoch: 9 [38400/60000 (64%)]	Loss: 0.000649
Train Epoch: 9 [51200/60000 (85%)]	Loss: 0.003020
==> Saving model ...

Test set: Average loss: 0.0350, Accuracy: 9905/10000 (99.05%)
Best Accuracy: 99.05%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 10 [0/60000 (0%)]	Loss: 0.001270
Train Epoch: 10 [12800/60000 (21%)]	Loss: 0.000292
Train Epoch: 10 [25600/60000 (43%)]	Loss: 0.002583
Train Epoch: 10 [38400/60000 (64%)]	Loss: 0.002510
Train Epoch: 10 [51200/60000 (85%)]	Loss: 0.010535
==> Saving model ...

Test set: Average loss: 0.0395, Accuracy: 9888/10000 (98.88%)
Best Accuracy: 98.88%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 11 [0/60000 (0%)]	Loss: 0.001320
Train Epoch: 11 [12800/60000 (21%)]	Loss: 0.000759
Train Epoch: 11 [25600/60000 (43%)]	Loss: 0.008772
Train Epoch: 11 [38400/60000 (64%)]	Loss: 0.001295
Train Epoch: 11 [51200/60000 (85%)]	Loss: 0.012488
==> Saving model ...

Test set: Average loss: 0.0396, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 12 [0/60000 (0%)]	Loss: 0.002639
Train Epoch: 12 [12800/60000 (21%)]	Loss: 0.009901
Train Epoch: 12 [25600/60000 (43%)]	Loss: 0.000344
Train Epoch: 12 [38400/60000 (64%)]	Loss: 0.026359
Train Epoch: 12 [51200/60000 (85%)]	Loss: 0.001002
==> Saving model ...

Test set: Average loss: 0.0384, Accuracy: 9905/10000 (99.05%)
Best Accuracy: 99.05%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 13 [0/60000 (0%)]	Loss: 0.001593
Train Epoch: 13 [12800/60000 (21%)]	Loss: 0.001651
Train Epoch: 13 [25600/60000 (43%)]	Loss: 0.023744
Train Epoch: 13 [38400/60000 (64%)]	Loss: 0.006323
Train Epoch: 13 [51200/60000 (85%)]	Loss: 0.003307
==> Saving model ...

Test set: Average loss: 0.0346, Accuracy: 9900/10000 (99.00%)
Best Accuracy: 99.00%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.1
Train Epoch: 14 [0/60000 (0%)]	Loss: 0.024166
Train Epoch: 14 [12800/60000 (21%)]	Loss: 0.001614
Train Epoch: 14 [25600/60000 (43%)]	Loss: 0.004642
Train Epoch: 14 [38400/60000 (64%)]	Loss: 0.001040
Train Epoch: 14 [51200/60000 (85%)]	Loss: 0.009383
==> Saving model ...

Test set: Average loss: 0.0382, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 15 [0/60000 (0%)]	Loss: 0.000844
Train Epoch: 15 [12800/60000 (21%)]	Loss: 0.004923
Train Epoch: 15 [25600/60000 (43%)]	Loss: 0.008255
Train Epoch: 15 [38400/60000 (64%)]	Loss: 0.000599
Train Epoch: 15 [51200/60000 (85%)]	Loss: 0.003088
==> Saving model ...

Test set: Average loss: 0.0264, Accuracy: 9914/10000 (99.14%)
Best Accuracy: 99.14%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 16 [0/60000 (0%)]	Loss: 0.001994
Train Epoch: 16 [12800/60000 (21%)]	Loss: 0.000609
Train Epoch: 16 [25600/60000 (43%)]	Loss: 0.000297
Train Epoch: 16 [38400/60000 (64%)]	Loss: 0.000320
Train Epoch: 16 [51200/60000 (85%)]	Loss: 0.000360
==> Saving model ...

Test set: Average loss: 0.0271, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 17 [0/60000 (0%)]	Loss: 0.000398
Train Epoch: 17 [12800/60000 (21%)]	Loss: 0.000561
Train Epoch: 17 [25600/60000 (43%)]	Loss: 0.000318
Train Epoch: 17 [38400/60000 (64%)]	Loss: 0.000463
Train Epoch: 17 [51200/60000 (85%)]	Loss: 0.000193
==> Saving model ...

Test set: Average loss: 0.0272, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 18 [0/60000 (0%)]	Loss: 0.000043
Train Epoch: 18 [12800/60000 (21%)]	Loss: 0.000276
Train Epoch: 18 [25600/60000 (43%)]	Loss: 0.001112
Train Epoch: 18 [38400/60000 (64%)]	Loss: 0.000539
Train Epoch: 18 [51200/60000 (85%)]	Loss: 0.000355
==> Saving model ...

Test set: Average loss: 0.0272, Accuracy: 9921/10000 (99.21%)
Best Accuracy: 99.21%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 19 [0/60000 (0%)]	Loss: 0.000626
Train Epoch: 19 [12800/60000 (21%)]	Loss: 0.000146
Train Epoch: 19 [25600/60000 (43%)]	Loss: 0.000997
Train Epoch: 19 [38400/60000 (64%)]	Loss: 0.000196
Train Epoch: 19 [51200/60000 (85%)]	Loss: 0.000509
==> Saving model ...

Test set: Average loss: 0.0275, Accuracy: 9921/10000 (99.21%)
Best Accuracy: 99.21%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 20 [0/60000 (0%)]	Loss: 0.001231
Train Epoch: 20 [12800/60000 (21%)]	Loss: 0.001630
Train Epoch: 20 [25600/60000 (43%)]	Loss: 0.000132
Train Epoch: 20 [38400/60000 (64%)]	Loss: 0.000741
Train Epoch: 20 [51200/60000 (85%)]	Loss: 0.000386
==> Saving model ...

Test set: Average loss: 0.0280, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 21 [0/60000 (0%)]	Loss: 0.000241
Train Epoch: 21 [12800/60000 (21%)]	Loss: 0.001153
Train Epoch: 21 [25600/60000 (43%)]	Loss: 0.000083
Train Epoch: 21 [38400/60000 (64%)]	Loss: 0.000243
Train Epoch: 21 [51200/60000 (85%)]	Loss: 0.000890
==> Saving model ...

Test set: Average loss: 0.0280, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 22 [0/60000 (0%)]	Loss: 0.000059
Train Epoch: 22 [12800/60000 (21%)]	Loss: 0.000417
Train Epoch: 22 [25600/60000 (43%)]	Loss: 0.001009
Train Epoch: 22 [38400/60000 (64%)]	Loss: 0.000425
Train Epoch: 22 [51200/60000 (85%)]	Loss: 0.000990
==> Saving model ...

Test set: Average loss: 0.0279, Accuracy: 9920/10000 (99.20%)
Best Accuracy: 99.20%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 23 [0/60000 (0%)]	Loss: 0.000102
Train Epoch: 23 [12800/60000 (21%)]	Loss: 0.000086
Train Epoch: 23 [25600/60000 (43%)]	Loss: 0.001304
Train Epoch: 23 [38400/60000 (64%)]	Loss: 0.005050
Train Epoch: 23 [51200/60000 (85%)]	Loss: 0.000269
==> Saving model ...

Test set: Average loss: 0.0329, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 24 [0/60000 (0%)]	Loss: 0.000230
Train Epoch: 24 [12800/60000 (21%)]	Loss: 0.000186
Train Epoch: 24 [25600/60000 (43%)]	Loss: 0.000647
Train Epoch: 24 [38400/60000 (64%)]	Loss: 0.000148
Train Epoch: 24 [51200/60000 (85%)]	Loss: 0.000547
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 25 [0/60000 (0%)]	Loss: 0.000303
Train Epoch: 25 [12800/60000 (21%)]	Loss: 0.000193
Train Epoch: 25 [25600/60000 (43%)]	Loss: 0.000748
Train Epoch: 25 [38400/60000 (64%)]	Loss: 0.000666
Train Epoch: 25 [51200/60000 (85%)]	Loss: 0.000070
==> Saving model ...

Test set: Average loss: 0.0282, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 26 [0/60000 (0%)]	Loss: 0.004265
Train Epoch: 26 [12800/60000 (21%)]	Loss: 0.001115
Train Epoch: 26 [25600/60000 (43%)]	Loss: 0.000026
Train Epoch: 26 [38400/60000 (64%)]	Loss: 0.001112
Train Epoch: 26 [51200/60000 (85%)]	Loss: 0.001507
==> Saving model ...

Test set: Average loss: 0.0283, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 27 [0/60000 (0%)]	Loss: 0.000594
Train Epoch: 27 [12800/60000 (21%)]	Loss: 0.001369
Train Epoch: 27 [25600/60000 (43%)]	Loss: 0.000330
Train Epoch: 27 [38400/60000 (64%)]	Loss: 0.001081
Train Epoch: 27 [51200/60000 (85%)]	Loss: 0.000085
==> Saving model ...

Test set: Average loss: 0.0283, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 28 [0/60000 (0%)]	Loss: 0.000432
Train Epoch: 28 [12800/60000 (21%)]	Loss: 0.000917
Train Epoch: 28 [25600/60000 (43%)]	Loss: 0.000662
Train Epoch: 28 [38400/60000 (64%)]	Loss: 0.000101
Train Epoch: 28 [51200/60000 (85%)]	Loss: 0.000727
==> Saving model ...

Test set: Average loss: 0.0284, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.010000000000000002
Train Epoch: 29 [0/60000 (0%)]	Loss: 0.000475
Train Epoch: 29 [12800/60000 (21%)]	Loss: 0.001508
Train Epoch: 29 [25600/60000 (43%)]	Loss: 0.000157
Train Epoch: 29 [38400/60000 (64%)]	Loss: 0.000699
Train Epoch: 29 [51200/60000 (85%)]	Loss: 0.000158
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 30 [0/60000 (0%)]	Loss: 0.000818
Train Epoch: 30 [12800/60000 (21%)]	Loss: 0.000225
Train Epoch: 30 [25600/60000 (43%)]	Loss: 0.000266
Train Epoch: 30 [38400/60000 (64%)]	Loss: 0.001036
Train Epoch: 30 [51200/60000 (85%)]	Loss: 0.000537
==> Saving model ...

Test set: Average loss: 0.0305, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 31 [0/60000 (0%)]	Loss: 0.000636
Train Epoch: 31 [12800/60000 (21%)]	Loss: 0.001760
Train Epoch: 31 [25600/60000 (43%)]	Loss: 0.000235
Train Epoch: 31 [38400/60000 (64%)]	Loss: 0.000941
Train Epoch: 31 [51200/60000 (85%)]	Loss: 0.000295
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 32 [0/60000 (0%)]	Loss: 0.005345
Train Epoch: 32 [12800/60000 (21%)]	Loss: 0.000356
Train Epoch: 32 [25600/60000 (43%)]	Loss: 0.000363
Train Epoch: 32 [38400/60000 (64%)]	Loss: 0.001614
Train Epoch: 32 [51200/60000 (85%)]	Loss: 0.004670
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 33 [0/60000 (0%)]	Loss: 0.001012
Train Epoch: 33 [12800/60000 (21%)]	Loss: 0.000277
Train Epoch: 33 [25600/60000 (43%)]	Loss: 0.000836
Train Epoch: 33 [38400/60000 (64%)]	Loss: 0.000155
Train Epoch: 33 [51200/60000 (85%)]	Loss: 0.000852
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 34 [0/60000 (0%)]	Loss: 0.000205
Train Epoch: 34 [12800/60000 (21%)]	Loss: 0.000554
Train Epoch: 34 [25600/60000 (43%)]	Loss: 0.000265
Train Epoch: 34 [38400/60000 (64%)]	Loss: 0.000542
Train Epoch: 34 [51200/60000 (85%)]	Loss: 0.000497
==> Saving model ...

Test set: Average loss: 0.0307, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 35 [0/60000 (0%)]	Loss: 0.000479
Train Epoch: 35 [12800/60000 (21%)]	Loss: 0.001733
Train Epoch: 35 [25600/60000 (43%)]	Loss: 0.000846
Train Epoch: 35 [38400/60000 (64%)]	Loss: 0.000230
Train Epoch: 35 [51200/60000 (85%)]	Loss: 0.000625
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 36 [0/60000 (0%)]	Loss: 0.000517
Train Epoch: 36 [12800/60000 (21%)]	Loss: 0.000060
Train Epoch: 36 [25600/60000 (43%)]	Loss: 0.000491
Train Epoch: 36 [38400/60000 (64%)]	Loss: 0.001317
Train Epoch: 36 [51200/60000 (85%)]	Loss: 0.000566
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 37 [0/60000 (0%)]	Loss: 0.000270
Train Epoch: 37 [12800/60000 (21%)]	Loss: 0.000244
Train Epoch: 37 [25600/60000 (43%)]	Loss: 0.000492
Train Epoch: 37 [38400/60000 (64%)]	Loss: 0.001952
Train Epoch: 37 [51200/60000 (85%)]	Loss: 0.000813
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 38 [0/60000 (0%)]	Loss: 0.000202
Train Epoch: 38 [12800/60000 (21%)]	Loss: 0.000635
Train Epoch: 38 [25600/60000 (43%)]	Loss: 0.000296
Train Epoch: 38 [38400/60000 (64%)]	Loss: 0.000042
Train Epoch: 38 [51200/60000 (85%)]	Loss: 0.000263
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 39 [0/60000 (0%)]	Loss: 0.001068
Train Epoch: 39 [12800/60000 (21%)]	Loss: 0.000326
Train Epoch: 39 [25600/60000 (43%)]	Loss: 0.000041
Train Epoch: 39 [38400/60000 (64%)]	Loss: 0.000060
Train Epoch: 39 [51200/60000 (85%)]	Loss: 0.000990
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 40 [0/60000 (0%)]	Loss: 0.000582
Train Epoch: 40 [12800/60000 (21%)]	Loss: 0.000800
Train Epoch: 40 [25600/60000 (43%)]	Loss: 0.000357
Train Epoch: 40 [38400/60000 (64%)]	Loss: 0.000058
Train Epoch: 40 [51200/60000 (85%)]	Loss: 0.000624
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 41 [0/60000 (0%)]	Loss: 0.000486
Train Epoch: 41 [12800/60000 (21%)]	Loss: 0.000220
Train Epoch: 41 [25600/60000 (43%)]	Loss: 0.000499
Train Epoch: 41 [38400/60000 (64%)]	Loss: 0.000586
Train Epoch: 41 [51200/60000 (85%)]	Loss: 0.000383
==> Saving model ...

Test set: Average loss: 0.0282, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 42 [0/60000 (0%)]	Loss: 0.000249
Train Epoch: 42 [12800/60000 (21%)]	Loss: 0.000625
Train Epoch: 42 [25600/60000 (43%)]	Loss: 0.000871
Train Epoch: 42 [38400/60000 (64%)]	Loss: 0.000394
Train Epoch: 42 [51200/60000 (85%)]	Loss: 0.001270
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 43 [0/60000 (0%)]	Loss: 0.001194
Train Epoch: 43 [12800/60000 (21%)]	Loss: 0.006845
Train Epoch: 43 [25600/60000 (43%)]	Loss: 0.000322
Train Epoch: 43 [38400/60000 (64%)]	Loss: 0.000237
Train Epoch: 43 [51200/60000 (85%)]	Loss: 0.000203
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.0010000000000000002
Train Epoch: 44 [0/60000 (0%)]	Loss: 0.000903
Train Epoch: 44 [12800/60000 (21%)]	Loss: 0.002343
Train Epoch: 44 [25600/60000 (43%)]	Loss: 0.000438
Train Epoch: 44 [38400/60000 (64%)]	Loss: 0.000579
Train Epoch: 44 [51200/60000 (85%)]	Loss: 0.000111
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 45 [0/60000 (0%)]	Loss: 0.000497
Train Epoch: 45 [12800/60000 (21%)]	Loss: 0.000453
Train Epoch: 45 [25600/60000 (43%)]	Loss: 0.000076
Train Epoch: 45 [38400/60000 (64%)]	Loss: 0.000273
Train Epoch: 45 [51200/60000 (85%)]	Loss: 0.000691
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 46 [0/60000 (0%)]	Loss: 0.000341
Train Epoch: 46 [12800/60000 (21%)]	Loss: 0.001239
Train Epoch: 46 [25600/60000 (43%)]	Loss: 0.001200
Train Epoch: 46 [38400/60000 (64%)]	Loss: 0.000521
Train Epoch: 46 [51200/60000 (85%)]	Loss: 0.000592
==> Saving model ...

Test set: Average loss: 0.0327, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 47 [0/60000 (0%)]	Loss: 0.000359
Train Epoch: 47 [12800/60000 (21%)]	Loss: 0.000302
Train Epoch: 47 [25600/60000 (43%)]	Loss: 0.000147
Train Epoch: 47 [38400/60000 (64%)]	Loss: 0.000890
Train Epoch: 47 [51200/60000 (85%)]	Loss: 0.000460
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 48 [0/60000 (0%)]	Loss: 0.000248
Train Epoch: 48 [12800/60000 (21%)]	Loss: 0.000490
Train Epoch: 48 [25600/60000 (43%)]	Loss: 0.000832
Train Epoch: 48 [38400/60000 (64%)]	Loss: 0.000142
Train Epoch: 48 [51200/60000 (85%)]	Loss: 0.000109
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 49 [0/60000 (0%)]	Loss: 0.000351
Train Epoch: 49 [12800/60000 (21%)]	Loss: 0.000928
Train Epoch: 49 [25600/60000 (43%)]	Loss: 0.002714
Train Epoch: 49 [38400/60000 (64%)]	Loss: 0.000722
Train Epoch: 49 [51200/60000 (85%)]	Loss: 0.001303
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 50 [0/60000 (0%)]	Loss: 0.003800
Train Epoch: 50 [12800/60000 (21%)]	Loss: 0.000257
Train Epoch: 50 [25600/60000 (43%)]	Loss: 0.000114
Train Epoch: 50 [38400/60000 (64%)]	Loss: 0.001245
Train Epoch: 50 [51200/60000 (85%)]	Loss: 0.001223
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 51 [0/60000 (0%)]	Loss: 0.000368
Train Epoch: 51 [12800/60000 (21%)]	Loss: 0.000831
Train Epoch: 51 [25600/60000 (43%)]	Loss: 0.000127
Train Epoch: 51 [38400/60000 (64%)]	Loss: 0.000173
Train Epoch: 51 [51200/60000 (85%)]	Loss: 0.000526
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 52 [0/60000 (0%)]	Loss: 0.000782
Train Epoch: 52 [12800/60000 (21%)]	Loss: 0.001797
Train Epoch: 52 [25600/60000 (43%)]	Loss: 0.000348
Train Epoch: 52 [38400/60000 (64%)]	Loss: 0.000315
Train Epoch: 52 [51200/60000 (85%)]	Loss: 0.000568
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 53 [0/60000 (0%)]	Loss: 0.000496
Train Epoch: 53 [12800/60000 (21%)]	Loss: 0.001005
Train Epoch: 53 [25600/60000 (43%)]	Loss: 0.000892
Train Epoch: 53 [38400/60000 (64%)]	Loss: 0.000074
Train Epoch: 53 [51200/60000 (85%)]	Loss: 0.000452
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 54 [0/60000 (0%)]	Loss: 0.001226
Train Epoch: 54 [12800/60000 (21%)]	Loss: 0.000222
Train Epoch: 54 [25600/60000 (43%)]	Loss: 0.001002
Train Epoch: 54 [38400/60000 (64%)]	Loss: 0.000428
Train Epoch: 54 [51200/60000 (85%)]	Loss: 0.000444
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 55 [0/60000 (0%)]	Loss: 0.001052
Train Epoch: 55 [12800/60000 (21%)]	Loss: 0.000378
Train Epoch: 55 [25600/60000 (43%)]	Loss: 0.000059
Train Epoch: 55 [38400/60000 (64%)]	Loss: 0.000476
Train Epoch: 55 [51200/60000 (85%)]	Loss: 0.000821
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 56 [0/60000 (0%)]	Loss: 0.000408
Train Epoch: 56 [12800/60000 (21%)]	Loss: 0.000553
Train Epoch: 56 [25600/60000 (43%)]	Loss: 0.000955
Train Epoch: 56 [38400/60000 (64%)]	Loss: 0.000138
Train Epoch: 56 [51200/60000 (85%)]	Loss: 0.000416
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 57 [0/60000 (0%)]	Loss: 0.000570
Train Epoch: 57 [12800/60000 (21%)]	Loss: 0.000505
Train Epoch: 57 [25600/60000 (43%)]	Loss: 0.001007
Train Epoch: 57 [38400/60000 (64%)]	Loss: 0.000274
Train Epoch: 57 [51200/60000 (85%)]	Loss: 0.001118
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 58 [0/60000 (0%)]	Loss: 0.000904
Train Epoch: 58 [12800/60000 (21%)]	Loss: 0.000247
Train Epoch: 58 [25600/60000 (43%)]	Loss: 0.000487
Train Epoch: 58 [38400/60000 (64%)]	Loss: 0.000333
Train Epoch: 58 [51200/60000 (85%)]	Loss: 0.000340
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000003
Train Epoch: 59 [0/60000 (0%)]	Loss: 0.000362
Train Epoch: 59 [12800/60000 (21%)]	Loss: 0.000253
Train Epoch: 59 [25600/60000 (43%)]	Loss: 0.000256
Train Epoch: 59 [38400/60000 (64%)]	Loss: 0.000423
Train Epoch: 59 [51200/60000 (85%)]	Loss: 0.000326
==> Saving model ...

Test set: Average loss: 0.0283, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------

Learning rate: 1.0000000000000003e-05
Train Epoch: 60 [0/60000 (0%)]	Loss: 0.001534
Train Epoch: 60 [12800/60000 (21%)]	Loss: 0.000079
Train Epoch: 60 [25600/60000 (43%)]	Loss: 0.000079
Train Epoch: 60 [38400/60000 (64%)]	Loss: 0.000106
Train Epoch: 60 [51200/60000 (85%)]	Loss: 0.000164
==> Saving model ...

Test set: Average loss: 0.0281, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:         70 /        200 (35.0%) weights are pruned
- Layer 1:       1280 /       3200 (40.0%) weights are pruned
- Layer 2:      19745 /      65536 (30.1%) weights are pruned
- Layer 3:        634 /       2560 (24.8%) weights are pruned
- Total  :      21729 /      71496 (30.4%) weights are pruned
------------------------------------------------------------------


==> Setting params:
batch_size : 128
test_batch_size : 128
epochs : 60
lr_epochs : 20
lr : 0.01
momentum : 0.9
weight_decay : 0.0001
no_cuda : False
seed : 1
log_interval : 100
arch : LeNet_5
pretrained : saved_models/LeNet_5.prune.intermittent.group_size5.0.pth.tar
evaluate : False
retrain : False
prune : intermittent
prune_target : None
stage : 1
group : [1, 1, 1, 5]
penalty : 0.0
pruning_ratio : 0.0
threshold : 0.0
with_sen : False
cuda : False
====================

LeNet_5(
  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv1): ReLU(inplace=True)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv2): ReLU(inplace=True)
  (pool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (ip1): Linear(in_features=256, out_features=256, bias=True)
  (relu_ip1): ReLU(inplace=True)
  (ip2): Linear(in_features=256, out_features=10, bias=True)
)
==> Start pruning ...
pruning_ratios: [0.35, 0.4, 0.3, 0.25]
------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 1 [0/60000 (0%)]	Loss: 0.076658
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.010470
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.002982
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.006561
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.006185
==> Saving model ...

Test set: Average loss: 0.0315, Accuracy: 9906/10000 (99.06%)
Best Accuracy: 99.06%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 2 [0/60000 (0%)]	Loss: 0.008637
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.004504
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.006351
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.001190
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.004367
==> Saving model ...

Test set: Average loss: 0.0302, Accuracy: 9912/10000 (99.12%)
Best Accuracy: 99.12%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 3 [0/60000 (0%)]	Loss: 0.011634
Train Epoch: 3 [12800/60000 (21%)]	Loss: 0.002290
Train Epoch: 3 [25600/60000 (43%)]	Loss: 0.004497
Train Epoch: 3 [38400/60000 (64%)]	Loss: 0.008342
Train Epoch: 3 [51200/60000 (85%)]	Loss: 0.001099
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9914/10000 (99.14%)
Best Accuracy: 99.14%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 4 [0/60000 (0%)]	Loss: 0.004131
Train Epoch: 4 [12800/60000 (21%)]	Loss: 0.002390
Train Epoch: 4 [25600/60000 (43%)]	Loss: 0.002551
Train Epoch: 4 [38400/60000 (64%)]	Loss: 0.007710
Train Epoch: 4 [51200/60000 (85%)]	Loss: 0.002256
==> Saving model ...

Test set: Average loss: 0.0292, Accuracy: 9916/10000 (99.16%)
Best Accuracy: 99.16%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 5 [0/60000 (0%)]	Loss: 0.006192
Train Epoch: 5 [12800/60000 (21%)]	Loss: 0.004610
Train Epoch: 5 [25600/60000 (43%)]	Loss: 0.000625
Train Epoch: 5 [38400/60000 (64%)]	Loss: 0.002755
Train Epoch: 5 [51200/60000 (85%)]	Loss: 0.008954
==> Saving model ...

Test set: Average loss: 0.0307, Accuracy: 9914/10000 (99.14%)
Best Accuracy: 99.14%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 6 [0/60000 (0%)]	Loss: 0.006313
Train Epoch: 6 [12800/60000 (21%)]	Loss: 0.001196
Train Epoch: 6 [25600/60000 (43%)]	Loss: 0.002165
Train Epoch: 6 [38400/60000 (64%)]	Loss: 0.006268
Train Epoch: 6 [51200/60000 (85%)]	Loss: 0.016217
==> Saving model ...

Test set: Average loss: 0.0286, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 7 [0/60000 (0%)]	Loss: 0.010013
Train Epoch: 7 [12800/60000 (21%)]	Loss: 0.012952
Train Epoch: 7 [25600/60000 (43%)]	Loss: 0.008231
Train Epoch: 7 [38400/60000 (64%)]	Loss: 0.003194
Train Epoch: 7 [51200/60000 (85%)]	Loss: 0.007732
==> Saving model ...

Test set: Average loss: 0.0303, Accuracy: 9916/10000 (99.16%)
Best Accuracy: 99.16%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 8 [0/60000 (0%)]	Loss: 0.002997
Train Epoch: 8 [12800/60000 (21%)]	Loss: 0.003037
Train Epoch: 8 [25600/60000 (43%)]	Loss: 0.000153
Train Epoch: 8 [38400/60000 (64%)]	Loss: 0.000779
Train Epoch: 8 [51200/60000 (85%)]	Loss: 0.007703
==> Saving model ...

Test set: Average loss: 0.0290, Accuracy: 9912/10000 (99.12%)
Best Accuracy: 99.12%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 9 [0/60000 (0%)]	Loss: 0.001333
Train Epoch: 9 [12800/60000 (21%)]	Loss: 0.002253
Train Epoch: 9 [25600/60000 (43%)]	Loss: 0.017029
Train Epoch: 9 [38400/60000 (64%)]	Loss: 0.003725
Train Epoch: 9 [51200/60000 (85%)]	Loss: 0.001427
==> Saving model ...

Test set: Average loss: 0.0293, Accuracy: 9915/10000 (99.15%)
Best Accuracy: 99.15%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 10 [0/60000 (0%)]	Loss: 0.001291
Train Epoch: 10 [12800/60000 (21%)]	Loss: 0.000589
Train Epoch: 10 [25600/60000 (43%)]	Loss: 0.001476
Train Epoch: 10 [38400/60000 (64%)]	Loss: 0.003485
Train Epoch: 10 [51200/60000 (85%)]	Loss: 0.003786
==> Saving model ...

Test set: Average loss: 0.0307, Accuracy: 9916/10000 (99.16%)
Best Accuracy: 99.16%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 11 [0/60000 (0%)]	Loss: 0.000803
Train Epoch: 11 [12800/60000 (21%)]	Loss: 0.000605
Train Epoch: 11 [25600/60000 (43%)]	Loss: 0.001613
Train Epoch: 11 [38400/60000 (64%)]	Loss: 0.001047
Train Epoch: 11 [51200/60000 (85%)]	Loss: 0.001227
==> Saving model ...

Test set: Average loss: 0.0290, Accuracy: 9921/10000 (99.21%)
Best Accuracy: 99.21%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 12 [0/60000 (0%)]	Loss: 0.001213
Train Epoch: 12 [12800/60000 (21%)]	Loss: 0.001111
Train Epoch: 12 [25600/60000 (43%)]	Loss: 0.000370
Train Epoch: 12 [38400/60000 (64%)]	Loss: 0.003322
Train Epoch: 12 [51200/60000 (85%)]	Loss: 0.000157
==> Saving model ...

Test set: Average loss: 0.0290, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 13 [0/60000 (0%)]	Loss: 0.002487
Train Epoch: 13 [12800/60000 (21%)]	Loss: 0.000950
Train Epoch: 13 [25600/60000 (43%)]	Loss: 0.002289
Train Epoch: 13 [38400/60000 (64%)]	Loss: 0.003849
Train Epoch: 13 [51200/60000 (85%)]	Loss: 0.003822
==> Saving model ...

Test set: Average loss: 0.0294, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 14 [0/60000 (0%)]	Loss: 0.002377
Train Epoch: 14 [12800/60000 (21%)]	Loss: 0.001112
Train Epoch: 14 [25600/60000 (43%)]	Loss: 0.001257
Train Epoch: 14 [38400/60000 (64%)]	Loss: 0.002482
Train Epoch: 14 [51200/60000 (85%)]	Loss: 0.002654
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 15 [0/60000 (0%)]	Loss: 0.000489
Train Epoch: 15 [12800/60000 (21%)]	Loss: 0.002812
Train Epoch: 15 [25600/60000 (43%)]	Loss: 0.003015
Train Epoch: 15 [38400/60000 (64%)]	Loss: 0.000320
Train Epoch: 15 [51200/60000 (85%)]	Loss: 0.002934
==> Saving model ...

Test set: Average loss: 0.0301, Accuracy: 9921/10000 (99.21%)
Best Accuracy: 99.21%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 16 [0/60000 (0%)]	Loss: 0.000990
Train Epoch: 16 [12800/60000 (21%)]	Loss: 0.001624
Train Epoch: 16 [25600/60000 (43%)]	Loss: 0.001382
Train Epoch: 16 [38400/60000 (64%)]	Loss: 0.004583
Train Epoch: 16 [51200/60000 (85%)]	Loss: 0.000263
==> Saving model ...

Test set: Average loss: 0.0301, Accuracy: 9913/10000 (99.13%)
Best Accuracy: 99.13%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 17 [0/60000 (0%)]	Loss: 0.000285
Train Epoch: 17 [12800/60000 (21%)]	Loss: 0.002195
Train Epoch: 17 [25600/60000 (43%)]	Loss: 0.001018
Train Epoch: 17 [38400/60000 (64%)]	Loss: 0.000799
Train Epoch: 17 [51200/60000 (85%)]	Loss: 0.000885
==> Saving model ...

Test set: Average loss: 0.0295, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 18 [0/60000 (0%)]	Loss: 0.000227
Train Epoch: 18 [12800/60000 (21%)]	Loss: 0.000288
Train Epoch: 18 [25600/60000 (43%)]	Loss: 0.003124
Train Epoch: 18 [38400/60000 (64%)]	Loss: 0.001535
Train Epoch: 18 [51200/60000 (85%)]	Loss: 0.002603
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 19 [0/60000 (0%)]	Loss: 0.001446
Train Epoch: 19 [12800/60000 (21%)]	Loss: 0.000639
Train Epoch: 19 [25600/60000 (43%)]	Loss: 0.002424
Train Epoch: 19 [38400/60000 (64%)]	Loss: 0.000464
Train Epoch: 19 [51200/60000 (85%)]	Loss: 0.000460
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 20 [0/60000 (0%)]	Loss: 0.002146
Train Epoch: 20 [12800/60000 (21%)]	Loss: 0.002568
Train Epoch: 20 [25600/60000 (43%)]	Loss: 0.000177
Train Epoch: 20 [38400/60000 (64%)]	Loss: 0.002972
Train Epoch: 20 [51200/60000 (85%)]	Loss: 0.001298
==> Saving model ...

Test set: Average loss: 0.0297, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 21 [0/60000 (0%)]	Loss: 0.001930
Train Epoch: 21 [12800/60000 (21%)]	Loss: 0.002993
Train Epoch: 21 [25600/60000 (43%)]	Loss: 0.001181
Train Epoch: 21 [38400/60000 (64%)]	Loss: 0.001299
Train Epoch: 21 [51200/60000 (85%)]	Loss: 0.000297
==> Saving model ...

Test set: Average loss: 0.0297, Accuracy: 9920/10000 (99.20%)
Best Accuracy: 99.20%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 22 [0/60000 (0%)]	Loss: 0.000143
Train Epoch: 22 [12800/60000 (21%)]	Loss: 0.002701
Train Epoch: 22 [25600/60000 (43%)]	Loss: 0.001909
Train Epoch: 22 [38400/60000 (64%)]	Loss: 0.000993
Train Epoch: 22 [51200/60000 (85%)]	Loss: 0.000186
==> Saving model ...

Test set: Average loss: 0.0298, Accuracy: 9920/10000 (99.20%)
Best Accuracy: 99.20%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 23 [0/60000 (0%)]	Loss: 0.000286
Train Epoch: 23 [12800/60000 (21%)]	Loss: 0.000624
Train Epoch: 23 [25600/60000 (43%)]	Loss: 0.001639
Train Epoch: 23 [38400/60000 (64%)]	Loss: 0.005897
Train Epoch: 23 [51200/60000 (85%)]	Loss: 0.000583
==> Saving model ...

Test set: Average loss: 0.0327, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 24 [0/60000 (0%)]	Loss: 0.000870
Train Epoch: 24 [12800/60000 (21%)]	Loss: 0.000722
Train Epoch: 24 [25600/60000 (43%)]	Loss: 0.001352
Train Epoch: 24 [38400/60000 (64%)]	Loss: 0.001654
Train Epoch: 24 [51200/60000 (85%)]	Loss: 0.000773
==> Saving model ...

Test set: Average loss: 0.0298, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 25 [0/60000 (0%)]	Loss: 0.000460
Train Epoch: 25 [12800/60000 (21%)]	Loss: 0.002216
Train Epoch: 25 [25600/60000 (43%)]	Loss: 0.002523
Train Epoch: 25 [38400/60000 (64%)]	Loss: 0.003157
Train Epoch: 25 [51200/60000 (85%)]	Loss: 0.000143
==> Saving model ...

Test set: Average loss: 0.0298, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 26 [0/60000 (0%)]	Loss: 0.006595
Train Epoch: 26 [12800/60000 (21%)]	Loss: 0.001679
Train Epoch: 26 [25600/60000 (43%)]	Loss: 0.000072
Train Epoch: 26 [38400/60000 (64%)]	Loss: 0.002439
Train Epoch: 26 [51200/60000 (85%)]	Loss: 0.001541
==> Saving model ...

Test set: Average loss: 0.0298, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 27 [0/60000 (0%)]	Loss: 0.001082
Train Epoch: 27 [12800/60000 (21%)]	Loss: 0.003855
Train Epoch: 27 [25600/60000 (43%)]	Loss: 0.001175
Train Epoch: 27 [38400/60000 (64%)]	Loss: 0.000768
Train Epoch: 27 [51200/60000 (85%)]	Loss: 0.000856
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 28 [0/60000 (0%)]	Loss: 0.002385
Train Epoch: 28 [12800/60000 (21%)]	Loss: 0.002377
Train Epoch: 28 [25600/60000 (43%)]	Loss: 0.001126
Train Epoch: 28 [38400/60000 (64%)]	Loss: 0.000151
Train Epoch: 28 [51200/60000 (85%)]	Loss: 0.001538
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 29 [0/60000 (0%)]	Loss: 0.001058
Train Epoch: 29 [12800/60000 (21%)]	Loss: 0.002313
Train Epoch: 29 [25600/60000 (43%)]	Loss: 0.000334
Train Epoch: 29 [38400/60000 (64%)]	Loss: 0.001413
Train Epoch: 29 [51200/60000 (85%)]	Loss: 0.001710
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 30 [0/60000 (0%)]	Loss: 0.001443
Train Epoch: 30 [12800/60000 (21%)]	Loss: 0.001695
Train Epoch: 30 [25600/60000 (43%)]	Loss: 0.000975
Train Epoch: 30 [38400/60000 (64%)]	Loss: 0.002660
Train Epoch: 30 [51200/60000 (85%)]	Loss: 0.001525
==> Saving model ...

Test set: Average loss: 0.0332, Accuracy: 9919/10000 (99.19%)
Best Accuracy: 99.19%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 31 [0/60000 (0%)]	Loss: 0.001351
Train Epoch: 31 [12800/60000 (21%)]	Loss: 0.001655
Train Epoch: 31 [25600/60000 (43%)]	Loss: 0.000993
Train Epoch: 31 [38400/60000 (64%)]	Loss: 0.002183
Train Epoch: 31 [51200/60000 (85%)]	Loss: 0.001870
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 32 [0/60000 (0%)]	Loss: 0.007451
Train Epoch: 32 [12800/60000 (21%)]	Loss: 0.000440
Train Epoch: 32 [25600/60000 (43%)]	Loss: 0.001776
Train Epoch: 32 [38400/60000 (64%)]	Loss: 0.002614
Train Epoch: 32 [51200/60000 (85%)]	Loss: 0.006406
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 33 [0/60000 (0%)]	Loss: 0.001796
Train Epoch: 33 [12800/60000 (21%)]	Loss: 0.000529
Train Epoch: 33 [25600/60000 (43%)]	Loss: 0.002763
Train Epoch: 33 [38400/60000 (64%)]	Loss: 0.000821
Train Epoch: 33 [51200/60000 (85%)]	Loss: 0.001618
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9916/10000 (99.16%)
Best Accuracy: 99.16%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 34 [0/60000 (0%)]	Loss: 0.000316
Train Epoch: 34 [12800/60000 (21%)]	Loss: 0.000900
Train Epoch: 34 [25600/60000 (43%)]	Loss: 0.000908
Train Epoch: 34 [38400/60000 (64%)]	Loss: 0.001360
Train Epoch: 34 [51200/60000 (85%)]	Loss: 0.001589
==> Saving model ...

Test set: Average loss: 0.0320, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 35 [0/60000 (0%)]	Loss: 0.000765
Train Epoch: 35 [12800/60000 (21%)]	Loss: 0.004614
Train Epoch: 35 [25600/60000 (43%)]	Loss: 0.003778
Train Epoch: 35 [38400/60000 (64%)]	Loss: 0.000887
Train Epoch: 35 [51200/60000 (85%)]	Loss: 0.002240
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 36 [0/60000 (0%)]	Loss: 0.000611
Train Epoch: 36 [12800/60000 (21%)]	Loss: 0.000193
Train Epoch: 36 [25600/60000 (43%)]	Loss: 0.000733
Train Epoch: 36 [38400/60000 (64%)]	Loss: 0.001424
Train Epoch: 36 [51200/60000 (85%)]	Loss: 0.000486
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 37 [0/60000 (0%)]	Loss: 0.001088
Train Epoch: 37 [12800/60000 (21%)]	Loss: 0.000453
Train Epoch: 37 [25600/60000 (43%)]	Loss: 0.002867
Train Epoch: 37 [38400/60000 (64%)]	Loss: 0.002677
Train Epoch: 37 [51200/60000 (85%)]	Loss: 0.001724
==> Saving model ...

Test set: Average loss: 0.0299, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 38 [0/60000 (0%)]	Loss: 0.002053
Train Epoch: 38 [12800/60000 (21%)]	Loss: 0.001826
Train Epoch: 38 [25600/60000 (43%)]	Loss: 0.000493
Train Epoch: 38 [38400/60000 (64%)]	Loss: 0.000081
Train Epoch: 38 [51200/60000 (85%)]	Loss: 0.000423
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 39 [0/60000 (0%)]	Loss: 0.003814
Train Epoch: 39 [12800/60000 (21%)]	Loss: 0.000718
Train Epoch: 39 [25600/60000 (43%)]	Loss: 0.000163
Train Epoch: 39 [38400/60000 (64%)]	Loss: 0.000880
Train Epoch: 39 [51200/60000 (85%)]	Loss: 0.001153
==> Saving model ...

Test set: Average loss: 0.0301, Accuracy: 9918/10000 (99.18%)
Best Accuracy: 99.18%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 40 [0/60000 (0%)]	Loss: 0.000523
Train Epoch: 40 [12800/60000 (21%)]	Loss: 0.002413
Train Epoch: 40 [25600/60000 (43%)]	Loss: 0.000814
Train Epoch: 40 [38400/60000 (64%)]	Loss: 0.000118
Train Epoch: 40 [51200/60000 (85%)]	Loss: 0.003119
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 41 [0/60000 (0%)]	Loss: 0.000645
Train Epoch: 41 [12800/60000 (21%)]	Loss: 0.000802
Train Epoch: 41 [25600/60000 (43%)]	Loss: 0.001095
Train Epoch: 41 [38400/60000 (64%)]	Loss: 0.001331
Train Epoch: 41 [51200/60000 (85%)]	Loss: 0.000566
==> Saving model ...

Test set: Average loss: 0.0312, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 42 [0/60000 (0%)]	Loss: 0.000870
Train Epoch: 42 [12800/60000 (21%)]	Loss: 0.001700
Train Epoch: 42 [25600/60000 (43%)]	Loss: 0.004579
Train Epoch: 42 [38400/60000 (64%)]	Loss: 0.000919
Train Epoch: 42 [51200/60000 (85%)]	Loss: 0.001611
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 43 [0/60000 (0%)]	Loss: 0.001454
Train Epoch: 43 [12800/60000 (21%)]	Loss: 0.014498
Train Epoch: 43 [25600/60000 (43%)]	Loss: 0.000702
Train Epoch: 43 [38400/60000 (64%)]	Loss: 0.001386
Train Epoch: 43 [51200/60000 (85%)]	Loss: 0.001236
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 44 [0/60000 (0%)]	Loss: 0.001146
Train Epoch: 44 [12800/60000 (21%)]	Loss: 0.000993
Train Epoch: 44 [25600/60000 (43%)]	Loss: 0.000945
Train Epoch: 44 [38400/60000 (64%)]	Loss: 0.001248
Train Epoch: 44 [51200/60000 (85%)]	Loss: 0.000416
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 45 [0/60000 (0%)]	Loss: 0.000884
Train Epoch: 45 [12800/60000 (21%)]	Loss: 0.000839
Train Epoch: 45 [25600/60000 (43%)]	Loss: 0.000119
Train Epoch: 45 [38400/60000 (64%)]	Loss: 0.001106
Train Epoch: 45 [51200/60000 (85%)]	Loss: 0.000933
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 46 [0/60000 (0%)]	Loss: 0.001532
Train Epoch: 46 [12800/60000 (21%)]	Loss: 0.005125
Train Epoch: 46 [25600/60000 (43%)]	Loss: 0.001134
Train Epoch: 46 [38400/60000 (64%)]	Loss: 0.001645
Train Epoch: 46 [51200/60000 (85%)]	Loss: 0.001616
==> Saving model ...

Test set: Average loss: 0.0329, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 47 [0/60000 (0%)]	Loss: 0.001124
Train Epoch: 47 [12800/60000 (21%)]	Loss: 0.000515
Train Epoch: 47 [25600/60000 (43%)]	Loss: 0.000838
Train Epoch: 47 [38400/60000 (64%)]	Loss: 0.000709
Train Epoch: 47 [51200/60000 (85%)]	Loss: 0.001442
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 48 [0/60000 (0%)]	Loss: 0.002017
Train Epoch: 48 [12800/60000 (21%)]	Loss: 0.001398
Train Epoch: 48 [25600/60000 (43%)]	Loss: 0.001263
Train Epoch: 48 [38400/60000 (64%)]	Loss: 0.000346
Train Epoch: 48 [51200/60000 (85%)]	Loss: 0.000095
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 49 [0/60000 (0%)]	Loss: 0.000569
Train Epoch: 49 [12800/60000 (21%)]	Loss: 0.002241
Train Epoch: 49 [25600/60000 (43%)]	Loss: 0.005316
Train Epoch: 49 [38400/60000 (64%)]	Loss: 0.001346
Train Epoch: 49 [51200/60000 (85%)]	Loss: 0.002231
==> Saving model ...

Test set: Average loss: 0.0303, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 50 [0/60000 (0%)]	Loss: 0.005653
Train Epoch: 50 [12800/60000 (21%)]	Loss: 0.000721
Train Epoch: 50 [25600/60000 (43%)]	Loss: 0.000650
Train Epoch: 50 [38400/60000 (64%)]	Loss: 0.002028
Train Epoch: 50 [51200/60000 (85%)]	Loss: 0.002753
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 51 [0/60000 (0%)]	Loss: 0.000707
Train Epoch: 51 [12800/60000 (21%)]	Loss: 0.001665
Train Epoch: 51 [25600/60000 (43%)]	Loss: 0.000441
Train Epoch: 51 [38400/60000 (64%)]	Loss: 0.000560
Train Epoch: 51 [51200/60000 (85%)]	Loss: 0.001652
==> Saving model ...

Test set: Average loss: 0.0301, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 52 [0/60000 (0%)]	Loss: 0.001729
Train Epoch: 52 [12800/60000 (21%)]	Loss: 0.002884
Train Epoch: 52 [25600/60000 (43%)]	Loss: 0.001422
Train Epoch: 52 [38400/60000 (64%)]	Loss: 0.001077
Train Epoch: 52 [51200/60000 (85%)]	Loss: 0.000900
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 53 [0/60000 (0%)]	Loss: 0.002275
Train Epoch: 53 [12800/60000 (21%)]	Loss: 0.001627
Train Epoch: 53 [25600/60000 (43%)]	Loss: 0.001184
Train Epoch: 53 [38400/60000 (64%)]	Loss: 0.000765
Train Epoch: 53 [51200/60000 (85%)]	Loss: 0.001872
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 54 [0/60000 (0%)]	Loss: 0.004332
Train Epoch: 54 [12800/60000 (21%)]	Loss: 0.000752
Train Epoch: 54 [25600/60000 (43%)]	Loss: 0.004590
Train Epoch: 54 [38400/60000 (64%)]	Loss: 0.001245
Train Epoch: 54 [51200/60000 (85%)]	Loss: 0.000994
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 55 [0/60000 (0%)]	Loss: 0.001919
Train Epoch: 55 [12800/60000 (21%)]	Loss: 0.001415
Train Epoch: 55 [25600/60000 (43%)]	Loss: 0.000143
Train Epoch: 55 [38400/60000 (64%)]	Loss: 0.001533
Train Epoch: 55 [51200/60000 (85%)]	Loss: 0.003268
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 56 [0/60000 (0%)]	Loss: 0.002052
Train Epoch: 56 [12800/60000 (21%)]	Loss: 0.000291
Train Epoch: 56 [25600/60000 (43%)]	Loss: 0.002341
Train Epoch: 56 [38400/60000 (64%)]	Loss: 0.000787
Train Epoch: 56 [51200/60000 (85%)]	Loss: 0.001290
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 57 [0/60000 (0%)]	Loss: 0.000814
Train Epoch: 57 [12800/60000 (21%)]	Loss: 0.001536
Train Epoch: 57 [25600/60000 (43%)]	Loss: 0.003630
Train Epoch: 57 [38400/60000 (64%)]	Loss: 0.001311
Train Epoch: 57 [51200/60000 (85%)]	Loss: 0.003044
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 58 [0/60000 (0%)]	Loss: 0.001446
Train Epoch: 58 [12800/60000 (21%)]	Loss: 0.000726
Train Epoch: 58 [25600/60000 (43%)]	Loss: 0.000764
Train Epoch: 58 [38400/60000 (64%)]	Loss: 0.001185
Train Epoch: 58 [51200/60000 (85%)]	Loss: 0.001404
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 59 [0/60000 (0%)]	Loss: 0.000386
Train Epoch: 59 [12800/60000 (21%)]	Loss: 0.000169
Train Epoch: 59 [25600/60000 (43%)]	Loss: 0.000380
Train Epoch: 59 [38400/60000 (64%)]	Loss: 0.001315
Train Epoch: 59 [51200/60000 (85%)]	Loss: 0.000421
==> Saving model ...

Test set: Average loss: 0.0308, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------

Learning rate: 1.0000000000000003e-05
Train Epoch: 60 [0/60000 (0%)]	Loss: 0.006679
Train Epoch: 60 [12800/60000 (21%)]	Loss: 0.000405
Train Epoch: 60 [25600/60000 (43%)]	Loss: 0.000187
Train Epoch: 60 [38400/60000 (64%)]	Loss: 0.000440
Train Epoch: 60 [51200/60000 (85%)]	Loss: 0.000829
==> Saving model ...

Test set: Average loss: 0.0300, Accuracy: 9917/10000 (99.17%)
Best Accuracy: 99.17%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        115 /        200 (57.5%) weights are pruned
- Layer 1:       2045 /       3200 (63.9%) weights are pruned
- Layer 2:      33645 /      65536 (51.3%) weights are pruned
- Layer 3:       1098 /       2560 (42.9%) weights are pruned
- Total  :      36903 /      71496 (51.6%) weights are pruned
------------------------------------------------------------------


==> Setting params:
batch_size : 128
test_batch_size : 128
epochs : 60
lr_epochs : 20
lr : 0.01
momentum : 0.9
weight_decay : 0.0001
no_cuda : False
seed : 1
log_interval : 100
arch : LeNet_5
pretrained : saved_models/LeNet_5.prune.intermittent.group_size5.1.pth.tar
evaluate : False
retrain : False
prune : intermittent
prune_target : None
stage : 2
group : [1, 1, 1, 5]
penalty : 0.0
pruning_ratio : 0.0
threshold : 0.0
with_sen : False
cuda : False
====================

LeNet_5(
  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv1): ReLU(inplace=True)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv2): ReLU(inplace=True)
  (pool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (ip1): Linear(in_features=256, out_features=256, bias=True)
  (relu_ip1): ReLU(inplace=True)
  (ip2): Linear(in_features=256, out_features=10, bias=True)
)
==> Start pruning ...
pruning_ratios: [0.35, 0.4, 0.3, 0.25]
------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 1 [0/60000 (0%)]	Loss: 0.599832
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.031427
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.041621
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.023131
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.022490
==> Saving model ...

Test set: Average loss: 0.0404, Accuracy: 9864/10000 (98.64%)
Best Accuracy: 98.64%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 2 [0/60000 (0%)]	Loss: 0.014918
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.008314
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.030414
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.006036
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.029028
==> Saving model ...

Test set: Average loss: 0.0371, Accuracy: 9884/10000 (98.84%)
Best Accuracy: 98.84%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 3 [0/60000 (0%)]	Loss: 0.018918
Train Epoch: 3 [12800/60000 (21%)]	Loss: 0.004411
Train Epoch: 3 [25600/60000 (43%)]	Loss: 0.019248
Train Epoch: 3 [38400/60000 (64%)]	Loss: 0.029290
Train Epoch: 3 [51200/60000 (85%)]	Loss: 0.007182
==> Saving model ...

Test set: Average loss: 0.0352, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 4 [0/60000 (0%)]	Loss: 0.004542
Train Epoch: 4 [12800/60000 (21%)]	Loss: 0.003185
Train Epoch: 4 [25600/60000 (43%)]	Loss: 0.005382
Train Epoch: 4 [38400/60000 (64%)]	Loss: 0.012022
Train Epoch: 4 [51200/60000 (85%)]	Loss: 0.034168
==> Saving model ...

Test set: Average loss: 0.0348, Accuracy: 9893/10000 (98.93%)
Best Accuracy: 98.93%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 5 [0/60000 (0%)]	Loss: 0.016841
Train Epoch: 5 [12800/60000 (21%)]	Loss: 0.006571
Train Epoch: 5 [25600/60000 (43%)]	Loss: 0.005029
Train Epoch: 5 [38400/60000 (64%)]	Loss: 0.004668
Train Epoch: 5 [51200/60000 (85%)]	Loss: 0.032952
==> Saving model ...

Test set: Average loss: 0.0397, Accuracy: 9878/10000 (98.78%)
Best Accuracy: 98.78%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 6 [0/60000 (0%)]	Loss: 0.012101
Train Epoch: 6 [12800/60000 (21%)]	Loss: 0.006877
Train Epoch: 6 [25600/60000 (43%)]	Loss: 0.017032
Train Epoch: 6 [38400/60000 (64%)]	Loss: 0.011189
Train Epoch: 6 [51200/60000 (85%)]	Loss: 0.012614
==> Saving model ...

Test set: Average loss: 0.0329, Accuracy: 9902/10000 (99.02%)
Best Accuracy: 99.02%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 7 [0/60000 (0%)]	Loss: 0.013713
Train Epoch: 7 [12800/60000 (21%)]	Loss: 0.021519
Train Epoch: 7 [25600/60000 (43%)]	Loss: 0.059186
Train Epoch: 7 [38400/60000 (64%)]	Loss: 0.019759
Train Epoch: 7 [51200/60000 (85%)]	Loss: 0.019284
==> Saving model ...

Test set: Average loss: 0.0365, Accuracy: 9901/10000 (99.01%)
Best Accuracy: 99.01%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 8 [0/60000 (0%)]	Loss: 0.004863
Train Epoch: 8 [12800/60000 (21%)]	Loss: 0.005525
Train Epoch: 8 [25600/60000 (43%)]	Loss: 0.001614
Train Epoch: 8 [38400/60000 (64%)]	Loss: 0.008397
Train Epoch: 8 [51200/60000 (85%)]	Loss: 0.003070
==> Saving model ...

Test set: Average loss: 0.0332, Accuracy: 9899/10000 (98.99%)
Best Accuracy: 98.99%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 9 [0/60000 (0%)]	Loss: 0.001893
Train Epoch: 9 [12800/60000 (21%)]	Loss: 0.005759
Train Epoch: 9 [25600/60000 (43%)]	Loss: 0.021518
Train Epoch: 9 [38400/60000 (64%)]	Loss: 0.011068
Train Epoch: 9 [51200/60000 (85%)]	Loss: 0.008814
==> Saving model ...

Test set: Average loss: 0.0330, Accuracy: 9904/10000 (99.04%)
Best Accuracy: 99.04%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 10 [0/60000 (0%)]	Loss: 0.003779
Train Epoch: 10 [12800/60000 (21%)]	Loss: 0.002528
Train Epoch: 10 [25600/60000 (43%)]	Loss: 0.003308
Train Epoch: 10 [38400/60000 (64%)]	Loss: 0.003006
Train Epoch: 10 [51200/60000 (85%)]	Loss: 0.003773
==> Saving model ...

Test set: Average loss: 0.0362, Accuracy: 9902/10000 (99.02%)
Best Accuracy: 99.02%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 11 [0/60000 (0%)]	Loss: 0.002501
Train Epoch: 11 [12800/60000 (21%)]	Loss: 0.004901
Train Epoch: 11 [25600/60000 (43%)]	Loss: 0.002225
Train Epoch: 11 [38400/60000 (64%)]	Loss: 0.004573
Train Epoch: 11 [51200/60000 (85%)]	Loss: 0.001102
==> Saving model ...

Test set: Average loss: 0.0334, Accuracy: 9905/10000 (99.05%)
Best Accuracy: 99.05%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 12 [0/60000 (0%)]	Loss: 0.001235
Train Epoch: 12 [12800/60000 (21%)]	Loss: 0.010105
Train Epoch: 12 [25600/60000 (43%)]	Loss: 0.001218
Train Epoch: 12 [38400/60000 (64%)]	Loss: 0.002826
Train Epoch: 12 [51200/60000 (85%)]	Loss: 0.002476
==> Saving model ...

Test set: Average loss: 0.0325, Accuracy: 9901/10000 (99.01%)
Best Accuracy: 99.01%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 13 [0/60000 (0%)]	Loss: 0.003157
Train Epoch: 13 [12800/60000 (21%)]	Loss: 0.002266
Train Epoch: 13 [25600/60000 (43%)]	Loss: 0.002304
Train Epoch: 13 [38400/60000 (64%)]	Loss: 0.007249
Train Epoch: 13 [51200/60000 (85%)]	Loss: 0.012433
==> Saving model ...

Test set: Average loss: 0.0343, Accuracy: 9900/10000 (99.00%)
Best Accuracy: 99.00%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 14 [0/60000 (0%)]	Loss: 0.003885
Train Epoch: 14 [12800/60000 (21%)]	Loss: 0.001725
Train Epoch: 14 [25600/60000 (43%)]	Loss: 0.003433
Train Epoch: 14 [38400/60000 (64%)]	Loss: 0.004057
Train Epoch: 14 [51200/60000 (85%)]	Loss: 0.003596
==> Saving model ...

Test set: Average loss: 0.0363, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 15 [0/60000 (0%)]	Loss: 0.000704
Train Epoch: 15 [12800/60000 (21%)]	Loss: 0.015575
Train Epoch: 15 [25600/60000 (43%)]	Loss: 0.008772
Train Epoch: 15 [38400/60000 (64%)]	Loss: 0.000229
Train Epoch: 15 [51200/60000 (85%)]	Loss: 0.001195
==> Saving model ...

Test set: Average loss: 0.0348, Accuracy: 9899/10000 (98.99%)
Best Accuracy: 98.99%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 16 [0/60000 (0%)]	Loss: 0.002327
Train Epoch: 16 [12800/60000 (21%)]	Loss: 0.006850
Train Epoch: 16 [25600/60000 (43%)]	Loss: 0.002173
Train Epoch: 16 [38400/60000 (64%)]	Loss: 0.003404
Train Epoch: 16 [51200/60000 (85%)]	Loss: 0.004212
==> Saving model ...

Test set: Average loss: 0.0352, Accuracy: 9902/10000 (99.02%)
Best Accuracy: 99.02%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 17 [0/60000 (0%)]	Loss: 0.001097
Train Epoch: 17 [12800/60000 (21%)]	Loss: 0.003433
Train Epoch: 17 [25600/60000 (43%)]	Loss: 0.005131
Train Epoch: 17 [38400/60000 (64%)]	Loss: 0.001736
Train Epoch: 17 [51200/60000 (85%)]	Loss: 0.001193
==> Saving model ...

Test set: Average loss: 0.0366, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 18 [0/60000 (0%)]	Loss: 0.000872
Train Epoch: 18 [12800/60000 (21%)]	Loss: 0.000678
Train Epoch: 18 [25600/60000 (43%)]	Loss: 0.012823
Train Epoch: 18 [38400/60000 (64%)]	Loss: 0.002433
Train Epoch: 18 [51200/60000 (85%)]	Loss: 0.004510
==> Saving model ...

Test set: Average loss: 0.0383, Accuracy: 9904/10000 (99.04%)
Best Accuracy: 99.04%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 19 [0/60000 (0%)]	Loss: 0.002950
Train Epoch: 19 [12800/60000 (21%)]	Loss: 0.000799
Train Epoch: 19 [25600/60000 (43%)]	Loss: 0.005627
Train Epoch: 19 [38400/60000 (64%)]	Loss: 0.001452
Train Epoch: 19 [51200/60000 (85%)]	Loss: 0.002770
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9901/10000 (99.01%)
Best Accuracy: 99.01%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 20 [0/60000 (0%)]	Loss: 0.003268
Train Epoch: 20 [12800/60000 (21%)]	Loss: 0.003939
Train Epoch: 20 [25600/60000 (43%)]	Loss: 0.001240
Train Epoch: 20 [38400/60000 (64%)]	Loss: 0.005004
Train Epoch: 20 [51200/60000 (85%)]	Loss: 0.001463
==> Saving model ...

Test set: Average loss: 0.0346, Accuracy: 9901/10000 (99.01%)
Best Accuracy: 99.01%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 21 [0/60000 (0%)]	Loss: 0.002714
Train Epoch: 21 [12800/60000 (21%)]	Loss: 0.004888
Train Epoch: 21 [25600/60000 (43%)]	Loss: 0.000831
Train Epoch: 21 [38400/60000 (64%)]	Loss: 0.001782
Train Epoch: 21 [51200/60000 (85%)]	Loss: 0.001440
==> Saving model ...

Test set: Average loss: 0.0349, Accuracy: 9902/10000 (99.02%)
Best Accuracy: 99.02%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 22 [0/60000 (0%)]	Loss: 0.000965
Train Epoch: 22 [12800/60000 (21%)]	Loss: 0.004734
Train Epoch: 22 [25600/60000 (43%)]	Loss: 0.003276
Train Epoch: 22 [38400/60000 (64%)]	Loss: 0.002192
Train Epoch: 22 [51200/60000 (85%)]	Loss: 0.000931
==> Saving model ...

Test set: Average loss: 0.0353, Accuracy: 9900/10000 (99.00%)
Best Accuracy: 99.00%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 23 [0/60000 (0%)]	Loss: 0.002507
Train Epoch: 23 [12800/60000 (21%)]	Loss: 0.001341
Train Epoch: 23 [25600/60000 (43%)]	Loss: 0.004982
Train Epoch: 23 [38400/60000 (64%)]	Loss: 0.005977
Train Epoch: 23 [51200/60000 (85%)]	Loss: 0.003034
==> Saving model ...

Test set: Average loss: 0.0405, Accuracy: 9899/10000 (98.99%)
Best Accuracy: 98.99%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 24 [0/60000 (0%)]	Loss: 0.001527
Train Epoch: 24 [12800/60000 (21%)]	Loss: 0.001070
Train Epoch: 24 [25600/60000 (43%)]	Loss: 0.002999
Train Epoch: 24 [38400/60000 (64%)]	Loss: 0.000909
Train Epoch: 24 [51200/60000 (85%)]	Loss: 0.002839
==> Saving model ...

Test set: Average loss: 0.0352, Accuracy: 9901/10000 (99.01%)
Best Accuracy: 99.01%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 25 [0/60000 (0%)]	Loss: 0.000715
Train Epoch: 25 [12800/60000 (21%)]	Loss: 0.001720
Train Epoch: 25 [25600/60000 (43%)]	Loss: 0.007018
Train Epoch: 25 [38400/60000 (64%)]	Loss: 0.003864
Train Epoch: 25 [51200/60000 (85%)]	Loss: 0.000677
==> Saving model ...

Test set: Average loss: 0.0352, Accuracy: 9900/10000 (99.00%)
Best Accuracy: 99.00%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 26 [0/60000 (0%)]	Loss: 0.007673
Train Epoch: 26 [12800/60000 (21%)]	Loss: 0.001549
Train Epoch: 26 [25600/60000 (43%)]	Loss: 0.000955
Train Epoch: 26 [38400/60000 (64%)]	Loss: 0.003425
Train Epoch: 26 [51200/60000 (85%)]	Loss: 0.001837
==> Saving model ...

Test set: Average loss: 0.0352, Accuracy: 9901/10000 (99.01%)
Best Accuracy: 99.01%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 27 [0/60000 (0%)]	Loss: 0.000632
Train Epoch: 27 [12800/60000 (21%)]	Loss: 0.003829
Train Epoch: 27 [25600/60000 (43%)]	Loss: 0.000500
Train Epoch: 27 [38400/60000 (64%)]	Loss: 0.001149
Train Epoch: 27 [51200/60000 (85%)]	Loss: 0.000455
==> Saving model ...

Test set: Average loss: 0.0353, Accuracy: 9900/10000 (99.00%)
Best Accuracy: 99.00%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 28 [0/60000 (0%)]	Loss: 0.002577
Train Epoch: 28 [12800/60000 (21%)]	Loss: 0.002297
Train Epoch: 28 [25600/60000 (43%)]	Loss: 0.001373
Train Epoch: 28 [38400/60000 (64%)]	Loss: 0.000946
Train Epoch: 28 [51200/60000 (85%)]	Loss: 0.001714
==> Saving model ...

Test set: Average loss: 0.0354, Accuracy: 9899/10000 (98.99%)
Best Accuracy: 98.99%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 29 [0/60000 (0%)]	Loss: 0.002238
Train Epoch: 29 [12800/60000 (21%)]	Loss: 0.004655
Train Epoch: 29 [25600/60000 (43%)]	Loss: 0.001283
Train Epoch: 29 [38400/60000 (64%)]	Loss: 0.001955
Train Epoch: 29 [51200/60000 (85%)]	Loss: 0.001917
==> Saving model ...

Test set: Average loss: 0.0353, Accuracy: 9900/10000 (99.00%)
Best Accuracy: 99.00%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 30 [0/60000 (0%)]	Loss: 0.000449
Train Epoch: 30 [12800/60000 (21%)]	Loss: 0.002075
Train Epoch: 30 [25600/60000 (43%)]	Loss: 0.003376
Train Epoch: 30 [38400/60000 (64%)]	Loss: 0.003559
Train Epoch: 30 [51200/60000 (85%)]	Loss: 0.001785
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 31 [0/60000 (0%)]	Loss: 0.002432
Train Epoch: 31 [12800/60000 (21%)]	Loss: 0.003932
Train Epoch: 31 [25600/60000 (43%)]	Loss: 0.002363
Train Epoch: 31 [38400/60000 (64%)]	Loss: 0.002483
Train Epoch: 31 [51200/60000 (85%)]	Loss: 0.003387
==> Saving model ...

Test set: Average loss: 0.0355, Accuracy: 9900/10000 (99.00%)
Best Accuracy: 99.00%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 32 [0/60000 (0%)]	Loss: 0.007280
Train Epoch: 32 [12800/60000 (21%)]	Loss: 0.001367
Train Epoch: 32 [25600/60000 (43%)]	Loss: 0.001636
Train Epoch: 32 [38400/60000 (64%)]	Loss: 0.008326
Train Epoch: 32 [51200/60000 (85%)]	Loss: 0.005370
==> Saving model ...

Test set: Average loss: 0.0355, Accuracy: 9899/10000 (98.99%)
Best Accuracy: 98.99%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 33 [0/60000 (0%)]	Loss: 0.002966
Train Epoch: 33 [12800/60000 (21%)]	Loss: 0.000951
Train Epoch: 33 [25600/60000 (43%)]	Loss: 0.003689
Train Epoch: 33 [38400/60000 (64%)]	Loss: 0.001191
Train Epoch: 33 [51200/60000 (85%)]	Loss: 0.001074
==> Saving model ...

Test set: Average loss: 0.0354, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 34 [0/60000 (0%)]	Loss: 0.003217
Train Epoch: 34 [12800/60000 (21%)]	Loss: 0.001341
Train Epoch: 34 [25600/60000 (43%)]	Loss: 0.004830
Train Epoch: 34 [38400/60000 (64%)]	Loss: 0.002077
Train Epoch: 34 [51200/60000 (85%)]	Loss: 0.002267
==> Saving model ...

Test set: Average loss: 0.0382, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 35 [0/60000 (0%)]	Loss: 0.001069
Train Epoch: 35 [12800/60000 (21%)]	Loss: 0.004939
Train Epoch: 35 [25600/60000 (43%)]	Loss: 0.002650
Train Epoch: 35 [38400/60000 (64%)]	Loss: 0.001963
Train Epoch: 35 [51200/60000 (85%)]	Loss: 0.003377
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9900/10000 (99.00%)
Best Accuracy: 99.00%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 36 [0/60000 (0%)]	Loss: 0.002038
Train Epoch: 36 [12800/60000 (21%)]	Loss: 0.000990
Train Epoch: 36 [25600/60000 (43%)]	Loss: 0.000472
Train Epoch: 36 [38400/60000 (64%)]	Loss: 0.002255
Train Epoch: 36 [51200/60000 (85%)]	Loss: 0.000863
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 37 [0/60000 (0%)]	Loss: 0.001690
Train Epoch: 37 [12800/60000 (21%)]	Loss: 0.000602
Train Epoch: 37 [25600/60000 (43%)]	Loss: 0.004017
Train Epoch: 37 [38400/60000 (64%)]	Loss: 0.002512
Train Epoch: 37 [51200/60000 (85%)]	Loss: 0.002613
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 38 [0/60000 (0%)]	Loss: 0.005422
Train Epoch: 38 [12800/60000 (21%)]	Loss: 0.003785
Train Epoch: 38 [25600/60000 (43%)]	Loss: 0.000747
Train Epoch: 38 [38400/60000 (64%)]	Loss: 0.000240
Train Epoch: 38 [51200/60000 (85%)]	Loss: 0.001897
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 39 [0/60000 (0%)]	Loss: 0.005895
Train Epoch: 39 [12800/60000 (21%)]	Loss: 0.001969
Train Epoch: 39 [25600/60000 (43%)]	Loss: 0.000433
Train Epoch: 39 [38400/60000 (64%)]	Loss: 0.001222
Train Epoch: 39 [51200/60000 (85%)]	Loss: 0.001702
==> Saving model ...

Test set: Average loss: 0.0359, Accuracy: 9899/10000 (98.99%)
Best Accuracy: 98.99%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 40 [0/60000 (0%)]	Loss: 0.001456
Train Epoch: 40 [12800/60000 (21%)]	Loss: 0.005440
Train Epoch: 40 [25600/60000 (43%)]	Loss: 0.002314
Train Epoch: 40 [38400/60000 (64%)]	Loss: 0.000477
Train Epoch: 40 [51200/60000 (85%)]	Loss: 0.002244
==> Saving model ...

Test set: Average loss: 0.0358, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 41 [0/60000 (0%)]	Loss: 0.001840
Train Epoch: 41 [12800/60000 (21%)]	Loss: 0.001035
Train Epoch: 41 [25600/60000 (43%)]	Loss: 0.000584
Train Epoch: 41 [38400/60000 (64%)]	Loss: 0.002490
Train Epoch: 41 [51200/60000 (85%)]	Loss: 0.001266
==> Saving model ...

Test set: Average loss: 0.0367, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 42 [0/60000 (0%)]	Loss: 0.001477
Train Epoch: 42 [12800/60000 (21%)]	Loss: 0.003526
Train Epoch: 42 [25600/60000 (43%)]	Loss: 0.004701
Train Epoch: 42 [38400/60000 (64%)]	Loss: 0.001660
Train Epoch: 42 [51200/60000 (85%)]	Loss: 0.002174
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 43 [0/60000 (0%)]	Loss: 0.001119
Train Epoch: 43 [12800/60000 (21%)]	Loss: 0.018249
Train Epoch: 43 [25600/60000 (43%)]	Loss: 0.001245
Train Epoch: 43 [38400/60000 (64%)]	Loss: 0.001014
Train Epoch: 43 [51200/60000 (85%)]	Loss: 0.001125
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 44 [0/60000 (0%)]	Loss: 0.001258
Train Epoch: 44 [12800/60000 (21%)]	Loss: 0.001749
Train Epoch: 44 [25600/60000 (43%)]	Loss: 0.001173
Train Epoch: 44 [38400/60000 (64%)]	Loss: 0.001285
Train Epoch: 44 [51200/60000 (85%)]	Loss: 0.001318
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 45 [0/60000 (0%)]	Loss: 0.002968
Train Epoch: 45 [12800/60000 (21%)]	Loss: 0.002709
Train Epoch: 45 [25600/60000 (43%)]	Loss: 0.000771
Train Epoch: 45 [38400/60000 (64%)]	Loss: 0.001242
Train Epoch: 45 [51200/60000 (85%)]	Loss: 0.001626
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 46 [0/60000 (0%)]	Loss: 0.001124
Train Epoch: 46 [12800/60000 (21%)]	Loss: 0.007561
Train Epoch: 46 [25600/60000 (43%)]	Loss: 0.001805
Train Epoch: 46 [38400/60000 (64%)]	Loss: 0.001678
Train Epoch: 46 [51200/60000 (85%)]	Loss: 0.001722
==> Saving model ...

Test set: Average loss: 0.0410, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 47 [0/60000 (0%)]	Loss: 0.002475
Train Epoch: 47 [12800/60000 (21%)]	Loss: 0.001050
Train Epoch: 47 [25600/60000 (43%)]	Loss: 0.002666
Train Epoch: 47 [38400/60000 (64%)]	Loss: 0.002139
Train Epoch: 47 [51200/60000 (85%)]	Loss: 0.001682
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 48 [0/60000 (0%)]	Loss: 0.002033
Train Epoch: 48 [12800/60000 (21%)]	Loss: 0.002829
Train Epoch: 48 [25600/60000 (43%)]	Loss: 0.003218
Train Epoch: 48 [38400/60000 (64%)]	Loss: 0.001543
Train Epoch: 48 [51200/60000 (85%)]	Loss: 0.000965
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 49 [0/60000 (0%)]	Loss: 0.001206
Train Epoch: 49 [12800/60000 (21%)]	Loss: 0.003363
Train Epoch: 49 [25600/60000 (43%)]	Loss: 0.008235
Train Epoch: 49 [38400/60000 (64%)]	Loss: 0.001194
Train Epoch: 49 [51200/60000 (85%)]	Loss: 0.003819
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 50 [0/60000 (0%)]	Loss: 0.008320
Train Epoch: 50 [12800/60000 (21%)]	Loss: 0.002459
Train Epoch: 50 [25600/60000 (43%)]	Loss: 0.001202
Train Epoch: 50 [38400/60000 (64%)]	Loss: 0.003234
Train Epoch: 50 [51200/60000 (85%)]	Loss: 0.006262
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 51 [0/60000 (0%)]	Loss: 0.000953
Train Epoch: 51 [12800/60000 (21%)]	Loss: 0.002806
Train Epoch: 51 [25600/60000 (43%)]	Loss: 0.000849
Train Epoch: 51 [38400/60000 (64%)]	Loss: 0.001423
Train Epoch: 51 [51200/60000 (85%)]	Loss: 0.003505
==> Saving model ...

Test set: Average loss: 0.0358, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 52 [0/60000 (0%)]	Loss: 0.002500
Train Epoch: 52 [12800/60000 (21%)]	Loss: 0.006302
Train Epoch: 52 [25600/60000 (43%)]	Loss: 0.004014
Train Epoch: 52 [38400/60000 (64%)]	Loss: 0.001208
Train Epoch: 52 [51200/60000 (85%)]	Loss: 0.001250
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 53 [0/60000 (0%)]	Loss: 0.001392
Train Epoch: 53 [12800/60000 (21%)]	Loss: 0.002977
Train Epoch: 53 [25600/60000 (43%)]	Loss: 0.001996
Train Epoch: 53 [38400/60000 (64%)]	Loss: 0.000868
Train Epoch: 53 [51200/60000 (85%)]	Loss: 0.002903
==> Saving model ...

Test set: Average loss: 0.0359, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 54 [0/60000 (0%)]	Loss: 0.006237
Train Epoch: 54 [12800/60000 (21%)]	Loss: 0.001283
Train Epoch: 54 [25600/60000 (43%)]	Loss: 0.003858
Train Epoch: 54 [38400/60000 (64%)]	Loss: 0.001737
Train Epoch: 54 [51200/60000 (85%)]	Loss: 0.001511
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 55 [0/60000 (0%)]	Loss: 0.002663
Train Epoch: 55 [12800/60000 (21%)]	Loss: 0.001932
Train Epoch: 55 [25600/60000 (43%)]	Loss: 0.000728
Train Epoch: 55 [38400/60000 (64%)]	Loss: 0.002730
Train Epoch: 55 [51200/60000 (85%)]	Loss: 0.009702
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 56 [0/60000 (0%)]	Loss: 0.001981
Train Epoch: 56 [12800/60000 (21%)]	Loss: 0.001068
Train Epoch: 56 [25600/60000 (43%)]	Loss: 0.006648
Train Epoch: 56 [38400/60000 (64%)]	Loss: 0.001143
Train Epoch: 56 [51200/60000 (85%)]	Loss: 0.002703
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 57 [0/60000 (0%)]	Loss: 0.001396
Train Epoch: 57 [12800/60000 (21%)]	Loss: 0.002805
Train Epoch: 57 [25600/60000 (43%)]	Loss: 0.005106
Train Epoch: 57 [38400/60000 (64%)]	Loss: 0.003463
Train Epoch: 57 [51200/60000 (85%)]	Loss: 0.010031
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 58 [0/60000 (0%)]	Loss: 0.002526
Train Epoch: 58 [12800/60000 (21%)]	Loss: 0.000536
Train Epoch: 58 [25600/60000 (43%)]	Loss: 0.001226
Train Epoch: 58 [38400/60000 (64%)]	Loss: 0.001657
Train Epoch: 58 [51200/60000 (85%)]	Loss: 0.005676
==> Saving model ...

Test set: Average loss: 0.0362, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 59 [0/60000 (0%)]	Loss: 0.000383
Train Epoch: 59 [12800/60000 (21%)]	Loss: 0.000359
Train Epoch: 59 [25600/60000 (43%)]	Loss: 0.001177
Train Epoch: 59 [38400/60000 (64%)]	Loss: 0.004354
Train Epoch: 59 [51200/60000 (85%)]	Loss: 0.000740
==> Saving model ...

Test set: Average loss: 0.0360, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------

Learning rate: 1.0000000000000003e-05
Train Epoch: 60 [0/60000 (0%)]	Loss: 0.008768
Train Epoch: 60 [12800/60000 (21%)]	Loss: 0.001162
Train Epoch: 60 [25600/60000 (43%)]	Loss: 0.000221
Train Epoch: 60 [38400/60000 (64%)]	Loss: 0.001032
Train Epoch: 60 [51200/60000 (85%)]	Loss: 0.001563
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        140 /        200 (70.0%) weights are pruned
- Layer 1:       2505 /       3200 (78.3%) weights are pruned
- Layer 2:      43437 /      65536 (66.3%) weights are pruned
- Layer 3:       1453 /       2560 (56.8%) weights are pruned
- Total  :      47535 /      71496 (66.5%) weights are pruned
------------------------------------------------------------------


==> Setting params:
batch_size : 128
test_batch_size : 128
epochs : 60
lr_epochs : 20
lr : 0.01
momentum : 0.9
weight_decay : 0.0001
no_cuda : False
seed : 1
log_interval : 100
arch : LeNet_5
pretrained : saved_models/LeNet_5.prune.intermittent.group_size5.2.pth.tar
evaluate : False
retrain : False
prune : intermittent
prune_target : None
stage : 3
group : [1, 1, 1, 5]
penalty : 0.0
pruning_ratio : 0.0
threshold : 0.0
with_sen : False
cuda : False
====================

LeNet_5(
  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv1): ReLU(inplace=True)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv2): ReLU(inplace=True)
  (pool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (ip1): Linear(in_features=256, out_features=256, bias=True)
  (relu_ip1): ReLU(inplace=True)
  (ip2): Linear(in_features=256, out_features=10, bias=True)
)
==> Start pruning ...
pruning_ratios: [0.35, 0.4, 0.3, 0.25]
------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 1 [0/60000 (0%)]	Loss: 0.311996
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.017328
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.036669
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.057923
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.013116
==> Saving model ...

Test set: Average loss: 0.0411, Accuracy: 9868/10000 (98.68%)
Best Accuracy: 98.68%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 2 [0/60000 (0%)]	Loss: 0.010436
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.040725
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.015458
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.005518
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.034145
==> Saving model ...

Test set: Average loss: 0.0396, Accuracy: 9867/10000 (98.67%)
Best Accuracy: 98.67%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 3 [0/60000 (0%)]	Loss: 0.037095
Train Epoch: 3 [12800/60000 (21%)]	Loss: 0.005673
Train Epoch: 3 [25600/60000 (43%)]	Loss: 0.029713
Train Epoch: 3 [38400/60000 (64%)]	Loss: 0.009244
Train Epoch: 3 [51200/60000 (85%)]	Loss: 0.023063
==> Saving model ...

Test set: Average loss: 0.0383, Accuracy: 9880/10000 (98.80%)
Best Accuracy: 98.80%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 4 [0/60000 (0%)]	Loss: 0.008812
Train Epoch: 4 [12800/60000 (21%)]	Loss: 0.009382
Train Epoch: 4 [25600/60000 (43%)]	Loss: 0.019158
Train Epoch: 4 [38400/60000 (64%)]	Loss: 0.011961
Train Epoch: 4 [51200/60000 (85%)]	Loss: 0.008654
==> Saving model ...

Test set: Average loss: 0.0411, Accuracy: 9870/10000 (98.70%)
Best Accuracy: 98.70%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 5 [0/60000 (0%)]	Loss: 0.019821
Train Epoch: 5 [12800/60000 (21%)]	Loss: 0.021305
Train Epoch: 5 [25600/60000 (43%)]	Loss: 0.009958
Train Epoch: 5 [38400/60000 (64%)]	Loss: 0.014930
Train Epoch: 5 [51200/60000 (85%)]	Loss: 0.012104
==> Saving model ...

Test set: Average loss: 0.0384, Accuracy: 9883/10000 (98.83%)
Best Accuracy: 98.83%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 6 [0/60000 (0%)]	Loss: 0.006591
Train Epoch: 6 [12800/60000 (21%)]	Loss: 0.010840
Train Epoch: 6 [25600/60000 (43%)]	Loss: 0.021535
Train Epoch: 6 [38400/60000 (64%)]	Loss: 0.020264
Train Epoch: 6 [51200/60000 (85%)]	Loss: 0.028193
==> Saving model ...

Test set: Average loss: 0.0355, Accuracy: 9885/10000 (98.85%)
Best Accuracy: 98.85%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 7 [0/60000 (0%)]	Loss: 0.021293
Train Epoch: 7 [12800/60000 (21%)]	Loss: 0.022204
Train Epoch: 7 [25600/60000 (43%)]	Loss: 0.051275
Train Epoch: 7 [38400/60000 (64%)]	Loss: 0.023213
Train Epoch: 7 [51200/60000 (85%)]	Loss: 0.037256
==> Saving model ...

Test set: Average loss: 0.0372, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 8 [0/60000 (0%)]	Loss: 0.003992
Train Epoch: 8 [12800/60000 (21%)]	Loss: 0.009641
Train Epoch: 8 [25600/60000 (43%)]	Loss: 0.002906
Train Epoch: 8 [38400/60000 (64%)]	Loss: 0.009006
Train Epoch: 8 [51200/60000 (85%)]	Loss: 0.009594
==> Saving model ...

Test set: Average loss: 0.0371, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 9 [0/60000 (0%)]	Loss: 0.002381
Train Epoch: 9 [12800/60000 (21%)]	Loss: 0.005156
Train Epoch: 9 [25600/60000 (43%)]	Loss: 0.025741
Train Epoch: 9 [38400/60000 (64%)]	Loss: 0.002526
Train Epoch: 9 [51200/60000 (85%)]	Loss: 0.007391
==> Saving model ...

Test set: Average loss: 0.0370, Accuracy: 9889/10000 (98.89%)
Best Accuracy: 98.89%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 10 [0/60000 (0%)]	Loss: 0.006730
Train Epoch: 10 [12800/60000 (21%)]	Loss: 0.004120
Train Epoch: 10 [25600/60000 (43%)]	Loss: 0.019107
Train Epoch: 10 [38400/60000 (64%)]	Loss: 0.001856
Train Epoch: 10 [51200/60000 (85%)]	Loss: 0.015076
==> Saving model ...

Test set: Average loss: 0.0408, Accuracy: 9886/10000 (98.86%)
Best Accuracy: 98.86%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 11 [0/60000 (0%)]	Loss: 0.006029
Train Epoch: 11 [12800/60000 (21%)]	Loss: 0.005761
Train Epoch: 11 [25600/60000 (43%)]	Loss: 0.007360
Train Epoch: 11 [38400/60000 (64%)]	Loss: 0.006785
Train Epoch: 11 [51200/60000 (85%)]	Loss: 0.005686
==> Saving model ...

Test set: Average loss: 0.0348, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 12 [0/60000 (0%)]	Loss: 0.003921
Train Epoch: 12 [12800/60000 (21%)]	Loss: 0.012778
Train Epoch: 12 [25600/60000 (43%)]	Loss: 0.001408
Train Epoch: 12 [38400/60000 (64%)]	Loss: 0.004932
Train Epoch: 12 [51200/60000 (85%)]	Loss: 0.001853
==> Saving model ...

Test set: Average loss: 0.0331, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 13 [0/60000 (0%)]	Loss: 0.003853
Train Epoch: 13 [12800/60000 (21%)]	Loss: 0.003147
Train Epoch: 13 [25600/60000 (43%)]	Loss: 0.002533
Train Epoch: 13 [38400/60000 (64%)]	Loss: 0.006585
Train Epoch: 13 [51200/60000 (85%)]	Loss: 0.013884
==> Saving model ...

Test set: Average loss: 0.0365, Accuracy: 9887/10000 (98.87%)
Best Accuracy: 98.87%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 14 [0/60000 (0%)]	Loss: 0.005725
Train Epoch: 14 [12800/60000 (21%)]	Loss: 0.001515
Train Epoch: 14 [25600/60000 (43%)]	Loss: 0.006292
Train Epoch: 14 [38400/60000 (64%)]	Loss: 0.008026
Train Epoch: 14 [51200/60000 (85%)]	Loss: 0.005657
==> Saving model ...

Test set: Average loss: 0.0389, Accuracy: 9885/10000 (98.85%)
Best Accuracy: 98.85%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 15 [0/60000 (0%)]	Loss: 0.008511
Train Epoch: 15 [12800/60000 (21%)]	Loss: 0.008154
Train Epoch: 15 [25600/60000 (43%)]	Loss: 0.015249
Train Epoch: 15 [38400/60000 (64%)]	Loss: 0.000969
Train Epoch: 15 [51200/60000 (85%)]	Loss: 0.001531
==> Saving model ...

Test set: Average loss: 0.0346, Accuracy: 9900/10000 (99.00%)
Best Accuracy: 99.00%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 16 [0/60000 (0%)]	Loss: 0.003099
Train Epoch: 16 [12800/60000 (21%)]	Loss: 0.007374
Train Epoch: 16 [25600/60000 (43%)]	Loss: 0.001428
Train Epoch: 16 [38400/60000 (64%)]	Loss: 0.004984
Train Epoch: 16 [51200/60000 (85%)]	Loss: 0.001772
==> Saving model ...

Test set: Average loss: 0.0380, Accuracy: 9886/10000 (98.86%)
Best Accuracy: 98.86%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 17 [0/60000 (0%)]	Loss: 0.001257
Train Epoch: 17 [12800/60000 (21%)]	Loss: 0.003901
Train Epoch: 17 [25600/60000 (43%)]	Loss: 0.017296
Train Epoch: 17 [38400/60000 (64%)]	Loss: 0.003352
Train Epoch: 17 [51200/60000 (85%)]	Loss: 0.001814
==> Saving model ...

Test set: Average loss: 0.0391, Accuracy: 9885/10000 (98.85%)
Best Accuracy: 98.85%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 18 [0/60000 (0%)]	Loss: 0.001462
Train Epoch: 18 [12800/60000 (21%)]	Loss: 0.000535
Train Epoch: 18 [25600/60000 (43%)]	Loss: 0.016565
Train Epoch: 18 [38400/60000 (64%)]	Loss: 0.005736
Train Epoch: 18 [51200/60000 (85%)]	Loss: 0.019839
==> Saving model ...

Test set: Average loss: 0.0388, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 19 [0/60000 (0%)]	Loss: 0.004833
Train Epoch: 19 [12800/60000 (21%)]	Loss: 0.002195
Train Epoch: 19 [25600/60000 (43%)]	Loss: 0.005536
Train Epoch: 19 [38400/60000 (64%)]	Loss: 0.001220
Train Epoch: 19 [51200/60000 (85%)]	Loss: 0.003109
==> Saving model ...

Test set: Average loss: 0.0354, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 20 [0/60000 (0%)]	Loss: 0.018562
Train Epoch: 20 [12800/60000 (21%)]	Loss: 0.007603
Train Epoch: 20 [25600/60000 (43%)]	Loss: 0.001725
Train Epoch: 20 [38400/60000 (64%)]	Loss: 0.006767
Train Epoch: 20 [51200/60000 (85%)]	Loss: 0.000949
==> Saving model ...

Test set: Average loss: 0.0352, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 21 [0/60000 (0%)]	Loss: 0.001568
Train Epoch: 21 [12800/60000 (21%)]	Loss: 0.002382
Train Epoch: 21 [25600/60000 (43%)]	Loss: 0.000527
Train Epoch: 21 [38400/60000 (64%)]	Loss: 0.012539
Train Epoch: 21 [51200/60000 (85%)]	Loss: 0.000945
==> Saving model ...

Test set: Average loss: 0.0351, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 22 [0/60000 (0%)]	Loss: 0.000906
Train Epoch: 22 [12800/60000 (21%)]	Loss: 0.004550
Train Epoch: 22 [25600/60000 (43%)]	Loss: 0.004029
Train Epoch: 22 [38400/60000 (64%)]	Loss: 0.001235
Train Epoch: 22 [51200/60000 (85%)]	Loss: 0.000961
==> Saving model ...

Test set: Average loss: 0.0373, Accuracy: 9893/10000 (98.93%)
Best Accuracy: 98.93%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 23 [0/60000 (0%)]	Loss: 0.002620
Train Epoch: 23 [12800/60000 (21%)]	Loss: 0.000703
Train Epoch: 23 [25600/60000 (43%)]	Loss: 0.003480
Train Epoch: 23 [38400/60000 (64%)]	Loss: 0.015883
Train Epoch: 23 [51200/60000 (85%)]	Loss: 0.002222
==> Saving model ...

Test set: Average loss: 0.0399, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 24 [0/60000 (0%)]	Loss: 0.001276
Train Epoch: 24 [12800/60000 (21%)]	Loss: 0.001642
Train Epoch: 24 [25600/60000 (43%)]	Loss: 0.003675
Train Epoch: 24 [38400/60000 (64%)]	Loss: 0.001689
Train Epoch: 24 [51200/60000 (85%)]	Loss: 0.001930
==> Saving model ...

Test set: Average loss: 0.0354, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 25 [0/60000 (0%)]	Loss: 0.002907
Train Epoch: 25 [12800/60000 (21%)]	Loss: 0.002524
Train Epoch: 25 [25600/60000 (43%)]	Loss: 0.004202
Train Epoch: 25 [38400/60000 (64%)]	Loss: 0.012156
Train Epoch: 25 [51200/60000 (85%)]	Loss: 0.002796
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9893/10000 (98.93%)
Best Accuracy: 98.93%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 26 [0/60000 (0%)]	Loss: 0.015651
Train Epoch: 26 [12800/60000 (21%)]	Loss: 0.003390
Train Epoch: 26 [25600/60000 (43%)]	Loss: 0.001129
Train Epoch: 26 [38400/60000 (64%)]	Loss: 0.009329
Train Epoch: 26 [51200/60000 (85%)]	Loss: 0.001410
==> Saving model ...

Test set: Average loss: 0.0355, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 27 [0/60000 (0%)]	Loss: 0.002664
Train Epoch: 27 [12800/60000 (21%)]	Loss: 0.002658
Train Epoch: 27 [25600/60000 (43%)]	Loss: 0.000531
Train Epoch: 27 [38400/60000 (64%)]	Loss: 0.002460
Train Epoch: 27 [51200/60000 (85%)]	Loss: 0.000548
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 28 [0/60000 (0%)]	Loss: 0.001619
Train Epoch: 28 [12800/60000 (21%)]	Loss: 0.003487
Train Epoch: 28 [25600/60000 (43%)]	Loss: 0.004126
Train Epoch: 28 [38400/60000 (64%)]	Loss: 0.001608
Train Epoch: 28 [51200/60000 (85%)]	Loss: 0.003255
==> Saving model ...

Test set: Average loss: 0.0356, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 29 [0/60000 (0%)]	Loss: 0.003122
Train Epoch: 29 [12800/60000 (21%)]	Loss: 0.005507
Train Epoch: 29 [25600/60000 (43%)]	Loss: 0.003638
Train Epoch: 29 [38400/60000 (64%)]	Loss: 0.001783
Train Epoch: 29 [51200/60000 (85%)]	Loss: 0.003064
==> Saving model ...

Test set: Average loss: 0.0355, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 30 [0/60000 (0%)]	Loss: 0.002048
Train Epoch: 30 [12800/60000 (21%)]	Loss: 0.001797
Train Epoch: 30 [25600/60000 (43%)]	Loss: 0.003204
Train Epoch: 30 [38400/60000 (64%)]	Loss: 0.005066
Train Epoch: 30 [51200/60000 (85%)]	Loss: 0.003224
==> Saving model ...

Test set: Average loss: 0.0367, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 31 [0/60000 (0%)]	Loss: 0.003630
Train Epoch: 31 [12800/60000 (21%)]	Loss: 0.004176
Train Epoch: 31 [25600/60000 (43%)]	Loss: 0.002433
Train Epoch: 31 [38400/60000 (64%)]	Loss: 0.001864
Train Epoch: 31 [51200/60000 (85%)]	Loss: 0.003262
==> Saving model ...

Test set: Average loss: 0.0362, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 32 [0/60000 (0%)]	Loss: 0.011420
Train Epoch: 32 [12800/60000 (21%)]	Loss: 0.001806
Train Epoch: 32 [25600/60000 (43%)]	Loss: 0.002070
Train Epoch: 32 [38400/60000 (64%)]	Loss: 0.007959
Train Epoch: 32 [51200/60000 (85%)]	Loss: 0.007731
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 33 [0/60000 (0%)]	Loss: 0.004195
Train Epoch: 33 [12800/60000 (21%)]	Loss: 0.002839
Train Epoch: 33 [25600/60000 (43%)]	Loss: 0.005152
Train Epoch: 33 [38400/60000 (64%)]	Loss: 0.001316
Train Epoch: 33 [51200/60000 (85%)]	Loss: 0.000840
==> Saving model ...

Test set: Average loss: 0.0357, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 34 [0/60000 (0%)]	Loss: 0.002728
Train Epoch: 34 [12800/60000 (21%)]	Loss: 0.004774
Train Epoch: 34 [25600/60000 (43%)]	Loss: 0.004443
Train Epoch: 34 [38400/60000 (64%)]	Loss: 0.002247
Train Epoch: 34 [51200/60000 (85%)]	Loss: 0.002209
==> Saving model ...

Test set: Average loss: 0.0374, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 35 [0/60000 (0%)]	Loss: 0.001924
Train Epoch: 35 [12800/60000 (21%)]	Loss: 0.006531
Train Epoch: 35 [25600/60000 (43%)]	Loss: 0.005089
Train Epoch: 35 [38400/60000 (64%)]	Loss: 0.002931
Train Epoch: 35 [51200/60000 (85%)]	Loss: 0.005378
==> Saving model ...

Test set: Average loss: 0.0359, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 36 [0/60000 (0%)]	Loss: 0.003065
Train Epoch: 36 [12800/60000 (21%)]	Loss: 0.001102
Train Epoch: 36 [25600/60000 (43%)]	Loss: 0.001359
Train Epoch: 36 [38400/60000 (64%)]	Loss: 0.004417
Train Epoch: 36 [51200/60000 (85%)]	Loss: 0.000274
==> Saving model ...

Test set: Average loss: 0.0360, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 37 [0/60000 (0%)]	Loss: 0.001489
Train Epoch: 37 [12800/60000 (21%)]	Loss: 0.000193
Train Epoch: 37 [25600/60000 (43%)]	Loss: 0.006728
Train Epoch: 37 [38400/60000 (64%)]	Loss: 0.003644
Train Epoch: 37 [51200/60000 (85%)]	Loss: 0.001854
==> Saving model ...

Test set: Average loss: 0.0360, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 38 [0/60000 (0%)]	Loss: 0.004422
Train Epoch: 38 [12800/60000 (21%)]	Loss: 0.004209
Train Epoch: 38 [25600/60000 (43%)]	Loss: 0.001052
Train Epoch: 38 [38400/60000 (64%)]	Loss: 0.000627
Train Epoch: 38 [51200/60000 (85%)]	Loss: 0.001669
==> Saving model ...

Test set: Average loss: 0.0359, Accuracy: 9898/10000 (98.98%)
Best Accuracy: 98.98%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 39 [0/60000 (0%)]	Loss: 0.006183
Train Epoch: 39 [12800/60000 (21%)]	Loss: 0.003709
Train Epoch: 39 [25600/60000 (43%)]	Loss: 0.000657
Train Epoch: 39 [38400/60000 (64%)]	Loss: 0.000278
Train Epoch: 39 [51200/60000 (85%)]	Loss: 0.001665
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9897/10000 (98.97%)
Best Accuracy: 98.97%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 40 [0/60000 (0%)]	Loss: 0.000513
Train Epoch: 40 [12800/60000 (21%)]	Loss: 0.001399
Train Epoch: 40 [25600/60000 (43%)]	Loss: 0.001868
Train Epoch: 40 [38400/60000 (64%)]	Loss: 0.000469
Train Epoch: 40 [51200/60000 (85%)]	Loss: 0.004466
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 41 [0/60000 (0%)]	Loss: 0.002114
Train Epoch: 41 [12800/60000 (21%)]	Loss: 0.000691
Train Epoch: 41 [25600/60000 (43%)]	Loss: 0.001057
Train Epoch: 41 [38400/60000 (64%)]	Loss: 0.002907
Train Epoch: 41 [51200/60000 (85%)]	Loss: 0.001155
==> Saving model ...

Test set: Average loss: 0.0363, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 42 [0/60000 (0%)]	Loss: 0.002855
Train Epoch: 42 [12800/60000 (21%)]	Loss: 0.002501
Train Epoch: 42 [25600/60000 (43%)]	Loss: 0.006859
Train Epoch: 42 [38400/60000 (64%)]	Loss: 0.000935
Train Epoch: 42 [51200/60000 (85%)]	Loss: 0.004800
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9896/10000 (98.96%)
Best Accuracy: 98.96%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 43 [0/60000 (0%)]	Loss: 0.002453
Train Epoch: 43 [12800/60000 (21%)]	Loss: 0.011195
Train Epoch: 43 [25600/60000 (43%)]	Loss: 0.002799
Train Epoch: 43 [38400/60000 (64%)]	Loss: 0.001578
Train Epoch: 43 [51200/60000 (85%)]	Loss: 0.004508
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 44 [0/60000 (0%)]	Loss: 0.003264
Train Epoch: 44 [12800/60000 (21%)]	Loss: 0.004262
Train Epoch: 44 [25600/60000 (43%)]	Loss: 0.001007
Train Epoch: 44 [38400/60000 (64%)]	Loss: 0.001259
Train Epoch: 44 [51200/60000 (85%)]	Loss: 0.001535
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 45 [0/60000 (0%)]	Loss: 0.004261
Train Epoch: 45 [12800/60000 (21%)]	Loss: 0.001508
Train Epoch: 45 [25600/60000 (43%)]	Loss: 0.001476
Train Epoch: 45 [38400/60000 (64%)]	Loss: 0.001625
Train Epoch: 45 [51200/60000 (85%)]	Loss: 0.002380
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 46 [0/60000 (0%)]	Loss: 0.002208
Train Epoch: 46 [12800/60000 (21%)]	Loss: 0.005037
Train Epoch: 46 [25600/60000 (43%)]	Loss: 0.002510
Train Epoch: 46 [38400/60000 (64%)]	Loss: 0.003423
Train Epoch: 46 [51200/60000 (85%)]	Loss: 0.002002
==> Saving model ...

Test set: Average loss: 0.0407, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 47 [0/60000 (0%)]	Loss: 0.001561
Train Epoch: 47 [12800/60000 (21%)]	Loss: 0.001193
Train Epoch: 47 [25600/60000 (43%)]	Loss: 0.002429
Train Epoch: 47 [38400/60000 (64%)]	Loss: 0.001925
Train Epoch: 47 [51200/60000 (85%)]	Loss: 0.000944
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 48 [0/60000 (0%)]	Loss: 0.002655
Train Epoch: 48 [12800/60000 (21%)]	Loss: 0.002236
Train Epoch: 48 [25600/60000 (43%)]	Loss: 0.005504
Train Epoch: 48 [38400/60000 (64%)]	Loss: 0.001013
Train Epoch: 48 [51200/60000 (85%)]	Loss: 0.000712
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 49 [0/60000 (0%)]	Loss: 0.001153
Train Epoch: 49 [12800/60000 (21%)]	Loss: 0.007103
Train Epoch: 49 [25600/60000 (43%)]	Loss: 0.007274
Train Epoch: 49 [38400/60000 (64%)]	Loss: 0.001620
Train Epoch: 49 [51200/60000 (85%)]	Loss: 0.005004
==> Saving model ...

Test set: Average loss: 0.0363, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 50 [0/60000 (0%)]	Loss: 0.008881
Train Epoch: 50 [12800/60000 (21%)]	Loss: 0.002453
Train Epoch: 50 [25600/60000 (43%)]	Loss: 0.001856
Train Epoch: 50 [38400/60000 (64%)]	Loss: 0.004073
Train Epoch: 50 [51200/60000 (85%)]	Loss: 0.004630
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 51 [0/60000 (0%)]	Loss: 0.001221
Train Epoch: 51 [12800/60000 (21%)]	Loss: 0.003498
Train Epoch: 51 [25600/60000 (43%)]	Loss: 0.001603
Train Epoch: 51 [38400/60000 (64%)]	Loss: 0.001256
Train Epoch: 51 [51200/60000 (85%)]	Loss: 0.005200
==> Saving model ...

Test set: Average loss: 0.0363, Accuracy: 9895/10000 (98.95%)
Best Accuracy: 98.95%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 52 [0/60000 (0%)]	Loss: 0.003251
Train Epoch: 52 [12800/60000 (21%)]	Loss: 0.008078
Train Epoch: 52 [25600/60000 (43%)]	Loss: 0.002782
Train Epoch: 52 [38400/60000 (64%)]	Loss: 0.002407
Train Epoch: 52 [51200/60000 (85%)]	Loss: 0.001916
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 53 [0/60000 (0%)]	Loss: 0.002507
Train Epoch: 53 [12800/60000 (21%)]	Loss: 0.001578
Train Epoch: 53 [25600/60000 (43%)]	Loss: 0.003809
Train Epoch: 53 [38400/60000 (64%)]	Loss: 0.001435
Train Epoch: 53 [51200/60000 (85%)]	Loss: 0.005350
==> Saving model ...

Test set: Average loss: 0.0379, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 54 [0/60000 (0%)]	Loss: 0.006608
Train Epoch: 54 [12800/60000 (21%)]	Loss: 0.000665
Train Epoch: 54 [25600/60000 (43%)]	Loss: 0.006699
Train Epoch: 54 [38400/60000 (64%)]	Loss: 0.002703
Train Epoch: 54 [51200/60000 (85%)]	Loss: 0.002680
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 55 [0/60000 (0%)]	Loss: 0.002404
Train Epoch: 55 [12800/60000 (21%)]	Loss: 0.002020
Train Epoch: 55 [25600/60000 (43%)]	Loss: 0.000244
Train Epoch: 55 [38400/60000 (64%)]	Loss: 0.001598
Train Epoch: 55 [51200/60000 (85%)]	Loss: 0.006859
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 56 [0/60000 (0%)]	Loss: 0.003994
Train Epoch: 56 [12800/60000 (21%)]	Loss: 0.002621
Train Epoch: 56 [25600/60000 (43%)]	Loss: 0.005739
Train Epoch: 56 [38400/60000 (64%)]	Loss: 0.002151
Train Epoch: 56 [51200/60000 (85%)]	Loss: 0.001084
==> Saving model ...

Test set: Average loss: 0.0362, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 57 [0/60000 (0%)]	Loss: 0.002907
Train Epoch: 57 [12800/60000 (21%)]	Loss: 0.006321
Train Epoch: 57 [25600/60000 (43%)]	Loss: 0.005720
Train Epoch: 57 [38400/60000 (64%)]	Loss: 0.003637
Train Epoch: 57 [51200/60000 (85%)]	Loss: 0.008494
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 58 [0/60000 (0%)]	Loss: 0.002888
Train Epoch: 58 [12800/60000 (21%)]	Loss: 0.000777
Train Epoch: 58 [25600/60000 (43%)]	Loss: 0.001623
Train Epoch: 58 [38400/60000 (64%)]	Loss: 0.001723
Train Epoch: 58 [51200/60000 (85%)]	Loss: 0.002553
==> Saving model ...

Test set: Average loss: 0.0364, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 59 [0/60000 (0%)]	Loss: 0.000910
Train Epoch: 59 [12800/60000 (21%)]	Loss: 0.000426
Train Epoch: 59 [25600/60000 (43%)]	Loss: 0.001292
Train Epoch: 59 [38400/60000 (64%)]	Loss: 0.006111
Train Epoch: 59 [51200/60000 (85%)]	Loss: 0.001764
==> Saving model ...

Test set: Average loss: 0.0377, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------

Learning rate: 1.0000000000000003e-05
Train Epoch: 60 [0/60000 (0%)]	Loss: 0.008208
Train Epoch: 60 [12800/60000 (21%)]	Loss: 0.000761
Train Epoch: 60 [25600/60000 (43%)]	Loss: 0.000595
Train Epoch: 60 [38400/60000 (64%)]	Loss: 0.000613
Train Epoch: 60 [51200/60000 (85%)]	Loss: 0.002061
==> Saving model ...

Test set: Average loss: 0.0361, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        160 /        200 (80.0%) weights are pruned
- Layer 1:       2780 /       3200 (86.9%) weights are pruned
- Layer 2:      50221 /      65536 (76.6%) weights are pruned
- Layer 3:       1723 /       2560 (67.3%) weights are pruned
- Total  :      54884 /      71496 (76.8%) weights are pruned
------------------------------------------------------------------


==> Setting params:
batch_size : 128
test_batch_size : 128
epochs : 60
lr_epochs : 20
lr : 0.01
momentum : 0.9
weight_decay : 0.0001
no_cuda : False
seed : 1
log_interval : 100
arch : LeNet_5
pretrained : saved_models/LeNet_5.prune.intermittent.group_size5.3.pth.tar
evaluate : False
retrain : False
prune : intermittent
prune_target : None
stage : 4
group : [1, 1, 1, 5]
penalty : 0.0
pruning_ratio : 0.0
threshold : 0.0
with_sen : False
cuda : False
====================

LeNet_5(
  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv1): ReLU(inplace=True)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv2): ReLU(inplace=True)
  (pool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (ip1): Linear(in_features=256, out_features=256, bias=True)
  (relu_ip1): ReLU(inplace=True)
  (ip2): Linear(in_features=256, out_features=10, bias=True)
)
==> Start pruning ...
pruning_ratios: [0.35, 0.4, 0.3, 0.25]
------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 1 [0/60000 (0%)]	Loss: 0.210378
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.024937
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.014307
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.020245
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.019021
==> Saving model ...

Test set: Average loss: 0.0437, Accuracy: 9871/10000 (98.71%)
Best Accuracy: 98.71%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 2 [0/60000 (0%)]	Loss: 0.014918
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.021448
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.002631
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.005007
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.011735
==> Saving model ...

Test set: Average loss: 0.0404, Accuracy: 9882/10000 (98.82%)
Best Accuracy: 98.82%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 3 [0/60000 (0%)]	Loss: 0.033264
Train Epoch: 3 [12800/60000 (21%)]	Loss: 0.002722
Train Epoch: 3 [25600/60000 (43%)]	Loss: 0.008805
Train Epoch: 3 [38400/60000 (64%)]	Loss: 0.023350
Train Epoch: 3 [51200/60000 (85%)]	Loss: 0.012195
==> Saving model ...

Test set: Average loss: 0.0433, Accuracy: 9879/10000 (98.79%)
Best Accuracy: 98.79%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 4 [0/60000 (0%)]	Loss: 0.017689
Train Epoch: 4 [12800/60000 (21%)]	Loss: 0.006768
Train Epoch: 4 [25600/60000 (43%)]	Loss: 0.013601
Train Epoch: 4 [38400/60000 (64%)]	Loss: 0.009147
Train Epoch: 4 [51200/60000 (85%)]	Loss: 0.004625
==> Saving model ...

Test set: Average loss: 0.0448, Accuracy: 9869/10000 (98.69%)
Best Accuracy: 98.69%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 5 [0/60000 (0%)]	Loss: 0.009030
Train Epoch: 5 [12800/60000 (21%)]	Loss: 0.005584
Train Epoch: 5 [25600/60000 (43%)]	Loss: 0.003873
Train Epoch: 5 [38400/60000 (64%)]	Loss: 0.009539
Train Epoch: 5 [51200/60000 (85%)]	Loss: 0.016608
==> Saving model ...

Test set: Average loss: 0.0457, Accuracy: 9879/10000 (98.79%)
Best Accuracy: 98.79%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 6 [0/60000 (0%)]	Loss: 0.002519
Train Epoch: 6 [12800/60000 (21%)]	Loss: 0.007587
Train Epoch: 6 [25600/60000 (43%)]	Loss: 0.033363
Train Epoch: 6 [38400/60000 (64%)]	Loss: 0.020188
Train Epoch: 6 [51200/60000 (85%)]	Loss: 0.026989
==> Saving model ...

Test set: Average loss: 0.0398, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 7 [0/60000 (0%)]	Loss: 0.034846
Train Epoch: 7 [12800/60000 (21%)]	Loss: 0.013717
Train Epoch: 7 [25600/60000 (43%)]	Loss: 0.040512
Train Epoch: 7 [38400/60000 (64%)]	Loss: 0.023475
Train Epoch: 7 [51200/60000 (85%)]	Loss: 0.036096
==> Saving model ...

Test set: Average loss: 0.0431, Accuracy: 9878/10000 (98.78%)
Best Accuracy: 98.78%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 8 [0/60000 (0%)]	Loss: 0.002400
Train Epoch: 8 [12800/60000 (21%)]	Loss: 0.016261
Train Epoch: 8 [25600/60000 (43%)]	Loss: 0.002690
Train Epoch: 8 [38400/60000 (64%)]	Loss: 0.006641
Train Epoch: 8 [51200/60000 (85%)]	Loss: 0.003870
==> Saving model ...

Test set: Average loss: 0.0398, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 9 [0/60000 (0%)]	Loss: 0.001846
Train Epoch: 9 [12800/60000 (21%)]	Loss: 0.006597
Train Epoch: 9 [25600/60000 (43%)]	Loss: 0.026905
Train Epoch: 9 [38400/60000 (64%)]	Loss: 0.008846
Train Epoch: 9 [51200/60000 (85%)]	Loss: 0.014536
==> Saving model ...

Test set: Average loss: 0.0423, Accuracy: 9885/10000 (98.85%)
Best Accuracy: 98.85%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 10 [0/60000 (0%)]	Loss: 0.006399
Train Epoch: 10 [12800/60000 (21%)]	Loss: 0.007056
Train Epoch: 10 [25600/60000 (43%)]	Loss: 0.012128
Train Epoch: 10 [38400/60000 (64%)]	Loss: 0.001741
Train Epoch: 10 [51200/60000 (85%)]	Loss: 0.006235
==> Saving model ...

Test set: Average loss: 0.0438, Accuracy: 9888/10000 (98.88%)
Best Accuracy: 98.88%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 11 [0/60000 (0%)]	Loss: 0.002394
Train Epoch: 11 [12800/60000 (21%)]	Loss: 0.003010
Train Epoch: 11 [25600/60000 (43%)]	Loss: 0.003779
Train Epoch: 11 [38400/60000 (64%)]	Loss: 0.007008
Train Epoch: 11 [51200/60000 (85%)]	Loss: 0.004076
==> Saving model ...

Test set: Average loss: 0.0410, Accuracy: 9880/10000 (98.80%)
Best Accuracy: 98.80%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 12 [0/60000 (0%)]	Loss: 0.002253
Train Epoch: 12 [12800/60000 (21%)]	Loss: 0.007393
Train Epoch: 12 [25600/60000 (43%)]	Loss: 0.001453
Train Epoch: 12 [38400/60000 (64%)]	Loss: 0.007664
Train Epoch: 12 [51200/60000 (85%)]	Loss: 0.006709
==> Saving model ...

Test set: Average loss: 0.0402, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 13 [0/60000 (0%)]	Loss: 0.003406
Train Epoch: 13 [12800/60000 (21%)]	Loss: 0.003603
Train Epoch: 13 [25600/60000 (43%)]	Loss: 0.003493
Train Epoch: 13 [38400/60000 (64%)]	Loss: 0.007398
Train Epoch: 13 [51200/60000 (85%)]	Loss: 0.007589
==> Saving model ...

Test set: Average loss: 0.0406, Accuracy: 9888/10000 (98.88%)
Best Accuracy: 98.88%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 14 [0/60000 (0%)]	Loss: 0.003988
Train Epoch: 14 [12800/60000 (21%)]	Loss: 0.002249
Train Epoch: 14 [25600/60000 (43%)]	Loss: 0.007489
Train Epoch: 14 [38400/60000 (64%)]	Loss: 0.005904
Train Epoch: 14 [51200/60000 (85%)]	Loss: 0.002835
==> Saving model ...

Test set: Average loss: 0.0428, Accuracy: 9884/10000 (98.84%)
Best Accuracy: 98.84%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 15 [0/60000 (0%)]	Loss: 0.003005
Train Epoch: 15 [12800/60000 (21%)]	Loss: 0.004607
Train Epoch: 15 [25600/60000 (43%)]	Loss: 0.008815
Train Epoch: 15 [38400/60000 (64%)]	Loss: 0.003560
Train Epoch: 15 [51200/60000 (85%)]	Loss: 0.002586
==> Saving model ...

Test set: Average loss: 0.0389, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 16 [0/60000 (0%)]	Loss: 0.004630
Train Epoch: 16 [12800/60000 (21%)]	Loss: 0.002419
Train Epoch: 16 [25600/60000 (43%)]	Loss: 0.001751
Train Epoch: 16 [38400/60000 (64%)]	Loss: 0.005505
Train Epoch: 16 [51200/60000 (85%)]	Loss: 0.001321
==> Saving model ...

Test set: Average loss: 0.0433, Accuracy: 9889/10000 (98.89%)
Best Accuracy: 98.89%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 17 [0/60000 (0%)]	Loss: 0.004305
Train Epoch: 17 [12800/60000 (21%)]	Loss: 0.003401
Train Epoch: 17 [25600/60000 (43%)]	Loss: 0.019599
Train Epoch: 17 [38400/60000 (64%)]	Loss: 0.004248
Train Epoch: 17 [51200/60000 (85%)]	Loss: 0.001301
==> Saving model ...

Test set: Average loss: 0.0440, Accuracy: 9886/10000 (98.86%)
Best Accuracy: 98.86%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 18 [0/60000 (0%)]	Loss: 0.001621
Train Epoch: 18 [12800/60000 (21%)]	Loss: 0.000757
Train Epoch: 18 [25600/60000 (43%)]	Loss: 0.011030
Train Epoch: 18 [38400/60000 (64%)]	Loss: 0.004093
Train Epoch: 18 [51200/60000 (85%)]	Loss: 0.011757
==> Saving model ...

Test set: Average loss: 0.0462, Accuracy: 9878/10000 (98.78%)
Best Accuracy: 98.78%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
Train Epoch: 19 [0/60000 (0%)]	Loss: 0.008283
Train Epoch: 19 [12800/60000 (21%)]	Loss: 0.002759
Train Epoch: 19 [25600/60000 (43%)]	Loss: 0.014075
Train Epoch: 19 [38400/60000 (64%)]	Loss: 0.001696
Train Epoch: 19 [51200/60000 (85%)]	Loss: 0.001080
==> Saving model ...

Test set: Average loss: 0.0435, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 20 [0/60000 (0%)]	Loss: 0.012099
Train Epoch: 20 [12800/60000 (21%)]	Loss: 0.004579
Train Epoch: 20 [25600/60000 (43%)]	Loss: 0.002338
Train Epoch: 20 [38400/60000 (64%)]	Loss: 0.006237
Train Epoch: 20 [51200/60000 (85%)]	Loss: 0.000896
==> Saving model ...

Test set: Average loss: 0.0409, Accuracy: 9893/10000 (98.93%)
Best Accuracy: 98.93%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 21 [0/60000 (0%)]	Loss: 0.002203
Train Epoch: 21 [12800/60000 (21%)]	Loss: 0.002431
Train Epoch: 21 [25600/60000 (43%)]	Loss: 0.001434
Train Epoch: 21 [38400/60000 (64%)]	Loss: 0.006500
Train Epoch: 21 [51200/60000 (85%)]	Loss: 0.001800
==> Saving model ...

Test set: Average loss: 0.0409, Accuracy: 9894/10000 (98.94%)
Best Accuracy: 98.94%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 22 [0/60000 (0%)]	Loss: 0.000244
Train Epoch: 22 [12800/60000 (21%)]	Loss: 0.002158
Train Epoch: 22 [25600/60000 (43%)]	Loss: 0.002822
Train Epoch: 22 [38400/60000 (64%)]	Loss: 0.001390
Train Epoch: 22 [51200/60000 (85%)]	Loss: 0.002631
==> Saving model ...

Test set: Average loss: 0.0411, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 23 [0/60000 (0%)]	Loss: 0.003088
Train Epoch: 23 [12800/60000 (21%)]	Loss: 0.000926
Train Epoch: 23 [25600/60000 (43%)]	Loss: 0.005273
Train Epoch: 23 [38400/60000 (64%)]	Loss: 0.008485
Train Epoch: 23 [51200/60000 (85%)]	Loss: 0.001136
==> Saving model ...

Test set: Average loss: 0.0471, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 24 [0/60000 (0%)]	Loss: 0.002002
Train Epoch: 24 [12800/60000 (21%)]	Loss: 0.001079
Train Epoch: 24 [25600/60000 (43%)]	Loss: 0.002109
Train Epoch: 24 [38400/60000 (64%)]	Loss: 0.002019
Train Epoch: 24 [51200/60000 (85%)]	Loss: 0.002212
==> Saving model ...

Test set: Average loss: 0.0410, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 25 [0/60000 (0%)]	Loss: 0.001521
Train Epoch: 25 [12800/60000 (21%)]	Loss: 0.002730
Train Epoch: 25 [25600/60000 (43%)]	Loss: 0.003959
Train Epoch: 25 [38400/60000 (64%)]	Loss: 0.005181
Train Epoch: 25 [51200/60000 (85%)]	Loss: 0.002553
==> Saving model ...

Test set: Average loss: 0.0411, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 26 [0/60000 (0%)]	Loss: 0.009053
Train Epoch: 26 [12800/60000 (21%)]	Loss: 0.004810
Train Epoch: 26 [25600/60000 (43%)]	Loss: 0.001280
Train Epoch: 26 [38400/60000 (64%)]	Loss: 0.006400
Train Epoch: 26 [51200/60000 (85%)]	Loss: 0.002508
==> Saving model ...

Test set: Average loss: 0.0409, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 27 [0/60000 (0%)]	Loss: 0.003334
Train Epoch: 27 [12800/60000 (21%)]	Loss: 0.002392
Train Epoch: 27 [25600/60000 (43%)]	Loss: 0.000635
Train Epoch: 27 [38400/60000 (64%)]	Loss: 0.001068
Train Epoch: 27 [51200/60000 (85%)]	Loss: 0.000516
==> Saving model ...

Test set: Average loss: 0.0410, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 28 [0/60000 (0%)]	Loss: 0.001322
Train Epoch: 28 [12800/60000 (21%)]	Loss: 0.001550
Train Epoch: 28 [25600/60000 (43%)]	Loss: 0.002363
Train Epoch: 28 [38400/60000 (64%)]	Loss: 0.001064
Train Epoch: 28 [51200/60000 (85%)]	Loss: 0.005255
==> Saving model ...

Test set: Average loss: 0.0413, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 29 [0/60000 (0%)]	Loss: 0.002673
Train Epoch: 29 [12800/60000 (21%)]	Loss: 0.006886
Train Epoch: 29 [25600/60000 (43%)]	Loss: 0.003101
Train Epoch: 29 [38400/60000 (64%)]	Loss: 0.001519
Train Epoch: 29 [51200/60000 (85%)]	Loss: 0.001814
==> Saving model ...

Test set: Average loss: 0.0411, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 30 [0/60000 (0%)]	Loss: 0.001634
Train Epoch: 30 [12800/60000 (21%)]	Loss: 0.001422
Train Epoch: 30 [25600/60000 (43%)]	Loss: 0.002791
Train Epoch: 30 [38400/60000 (64%)]	Loss: 0.008204
Train Epoch: 30 [51200/60000 (85%)]	Loss: 0.001860
==> Saving model ...

Test set: Average loss: 0.0447, Accuracy: 9888/10000 (98.88%)
Best Accuracy: 98.88%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 31 [0/60000 (0%)]	Loss: 0.003866
Train Epoch: 31 [12800/60000 (21%)]	Loss: 0.005383
Train Epoch: 31 [25600/60000 (43%)]	Loss: 0.001953
Train Epoch: 31 [38400/60000 (64%)]	Loss: 0.002549
Train Epoch: 31 [51200/60000 (85%)]	Loss: 0.002117
==> Saving model ...

Test set: Average loss: 0.0417, Accuracy: 9888/10000 (98.88%)
Best Accuracy: 98.88%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 32 [0/60000 (0%)]	Loss: 0.005704
Train Epoch: 32 [12800/60000 (21%)]	Loss: 0.002407
Train Epoch: 32 [25600/60000 (43%)]	Loss: 0.002739
Train Epoch: 32 [38400/60000 (64%)]	Loss: 0.013039
Train Epoch: 32 [51200/60000 (85%)]	Loss: 0.007218
==> Saving model ...

Test set: Average loss: 0.0412, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 33 [0/60000 (0%)]	Loss: 0.003275
Train Epoch: 33 [12800/60000 (21%)]	Loss: 0.001641
Train Epoch: 33 [25600/60000 (43%)]	Loss: 0.005825
Train Epoch: 33 [38400/60000 (64%)]	Loss: 0.000785
Train Epoch: 33 [51200/60000 (85%)]	Loss: 0.000642
==> Saving model ...

Test set: Average loss: 0.0409, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 34 [0/60000 (0%)]	Loss: 0.001078
Train Epoch: 34 [12800/60000 (21%)]	Loss: 0.004998
Train Epoch: 34 [25600/60000 (43%)]	Loss: 0.002611
Train Epoch: 34 [38400/60000 (64%)]	Loss: 0.002445
Train Epoch: 34 [51200/60000 (85%)]	Loss: 0.001505
==> Saving model ...

Test set: Average loss: 0.0439, Accuracy: 9889/10000 (98.89%)
Best Accuracy: 98.89%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 35 [0/60000 (0%)]	Loss: 0.001601
Train Epoch: 35 [12800/60000 (21%)]	Loss: 0.003342
Train Epoch: 35 [25600/60000 (43%)]	Loss: 0.005374
Train Epoch: 35 [38400/60000 (64%)]	Loss: 0.004493
Train Epoch: 35 [51200/60000 (85%)]	Loss: 0.002374
==> Saving model ...

Test set: Average loss: 0.0413, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 36 [0/60000 (0%)]	Loss: 0.002989
Train Epoch: 36 [12800/60000 (21%)]	Loss: 0.000472
Train Epoch: 36 [25600/60000 (43%)]	Loss: 0.002291
Train Epoch: 36 [38400/60000 (64%)]	Loss: 0.004022
Train Epoch: 36 [51200/60000 (85%)]	Loss: 0.000887
==> Saving model ...

Test set: Average loss: 0.0414, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 37 [0/60000 (0%)]	Loss: 0.001137
Train Epoch: 37 [12800/60000 (21%)]	Loss: 0.000549
Train Epoch: 37 [25600/60000 (43%)]	Loss: 0.002375
Train Epoch: 37 [38400/60000 (64%)]	Loss: 0.003927
Train Epoch: 37 [51200/60000 (85%)]	Loss: 0.001955
==> Saving model ...

Test set: Average loss: 0.0417, Accuracy: 9889/10000 (98.89%)
Best Accuracy: 98.89%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 38 [0/60000 (0%)]	Loss: 0.005528
Train Epoch: 38 [12800/60000 (21%)]	Loss: 0.001959
Train Epoch: 38 [25600/60000 (43%)]	Loss: 0.001126
Train Epoch: 38 [38400/60000 (64%)]	Loss: 0.001453
Train Epoch: 38 [51200/60000 (85%)]	Loss: 0.002334
==> Saving model ...

Test set: Average loss: 0.0413, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.001
Train Epoch: 39 [0/60000 (0%)]	Loss: 0.005507
Train Epoch: 39 [12800/60000 (21%)]	Loss: 0.002777
Train Epoch: 39 [25600/60000 (43%)]	Loss: 0.000507
Train Epoch: 39 [38400/60000 (64%)]	Loss: 0.000160
Train Epoch: 39 [51200/60000 (85%)]	Loss: 0.003431
==> Saving model ...

Test set: Average loss: 0.0416, Accuracy: 9888/10000 (98.88%)
Best Accuracy: 98.88%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 40 [0/60000 (0%)]	Loss: 0.000723
Train Epoch: 40 [12800/60000 (21%)]	Loss: 0.002661
Train Epoch: 40 [25600/60000 (43%)]	Loss: 0.003027
Train Epoch: 40 [38400/60000 (64%)]	Loss: 0.000916
Train Epoch: 40 [51200/60000 (85%)]	Loss: 0.002950
==> Saving model ...

Test set: Average loss: 0.0415, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 41 [0/60000 (0%)]	Loss: 0.002425
Train Epoch: 41 [12800/60000 (21%)]	Loss: 0.000208
Train Epoch: 41 [25600/60000 (43%)]	Loss: 0.000888
Train Epoch: 41 [38400/60000 (64%)]	Loss: 0.001581
Train Epoch: 41 [51200/60000 (85%)]	Loss: 0.001445
==> Saving model ...

Test set: Average loss: 0.0425, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 42 [0/60000 (0%)]	Loss: 0.001934
Train Epoch: 42 [12800/60000 (21%)]	Loss: 0.002677
Train Epoch: 42 [25600/60000 (43%)]	Loss: 0.005102
Train Epoch: 42 [38400/60000 (64%)]	Loss: 0.000625
Train Epoch: 42 [51200/60000 (85%)]	Loss: 0.004123
==> Saving model ...

Test set: Average loss: 0.0415, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 43 [0/60000 (0%)]	Loss: 0.001896
Train Epoch: 43 [12800/60000 (21%)]	Loss: 0.013573
Train Epoch: 43 [25600/60000 (43%)]	Loss: 0.004082
Train Epoch: 43 [38400/60000 (64%)]	Loss: 0.001511
Train Epoch: 43 [51200/60000 (85%)]	Loss: 0.001512
==> Saving model ...

Test set: Average loss: 0.0415, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 44 [0/60000 (0%)]	Loss: 0.002024
Train Epoch: 44 [12800/60000 (21%)]	Loss: 0.003678
Train Epoch: 44 [25600/60000 (43%)]	Loss: 0.001009
Train Epoch: 44 [38400/60000 (64%)]	Loss: 0.001276
Train Epoch: 44 [51200/60000 (85%)]	Loss: 0.000744
==> Saving model ...

Test set: Average loss: 0.0415, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 45 [0/60000 (0%)]	Loss: 0.003534
Train Epoch: 45 [12800/60000 (21%)]	Loss: 0.000501
Train Epoch: 45 [25600/60000 (43%)]	Loss: 0.000577
Train Epoch: 45 [38400/60000 (64%)]	Loss: 0.001730
Train Epoch: 45 [51200/60000 (85%)]	Loss: 0.001557
==> Saving model ...

Test set: Average loss: 0.0415, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 46 [0/60000 (0%)]	Loss: 0.000997
Train Epoch: 46 [12800/60000 (21%)]	Loss: 0.003848
Train Epoch: 46 [25600/60000 (43%)]	Loss: 0.003450
Train Epoch: 46 [38400/60000 (64%)]	Loss: 0.001951
Train Epoch: 46 [51200/60000 (85%)]	Loss: 0.001284
==> Saving model ...

Test set: Average loss: 0.0477, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 47 [0/60000 (0%)]	Loss: 0.002013
Train Epoch: 47 [12800/60000 (21%)]	Loss: 0.002386
Train Epoch: 47 [25600/60000 (43%)]	Loss: 0.001147
Train Epoch: 47 [38400/60000 (64%)]	Loss: 0.002726
Train Epoch: 47 [51200/60000 (85%)]	Loss: 0.001672
==> Saving model ...

Test set: Average loss: 0.0415, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 48 [0/60000 (0%)]	Loss: 0.001156
Train Epoch: 48 [12800/60000 (21%)]	Loss: 0.001302
Train Epoch: 48 [25600/60000 (43%)]	Loss: 0.007104
Train Epoch: 48 [38400/60000 (64%)]	Loss: 0.004461
Train Epoch: 48 [51200/60000 (85%)]	Loss: 0.001002
==> Saving model ...

Test set: Average loss: 0.0415, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 49 [0/60000 (0%)]	Loss: 0.000903
Train Epoch: 49 [12800/60000 (21%)]	Loss: 0.004512
Train Epoch: 49 [25600/60000 (43%)]	Loss: 0.007640
Train Epoch: 49 [38400/60000 (64%)]	Loss: 0.001607
Train Epoch: 49 [51200/60000 (85%)]	Loss: 0.003963
==> Saving model ...

Test set: Average loss: 0.0446, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 50 [0/60000 (0%)]	Loss: 0.007964
Train Epoch: 50 [12800/60000 (21%)]	Loss: 0.002564
Train Epoch: 50 [25600/60000 (43%)]	Loss: 0.001378
Train Epoch: 50 [38400/60000 (64%)]	Loss: 0.003894
Train Epoch: 50 [51200/60000 (85%)]	Loss: 0.003274
==> Saving model ...

Test set: Average loss: 0.0415, Accuracy: 9891/10000 (98.91%)
Best Accuracy: 98.91%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 51 [0/60000 (0%)]	Loss: 0.001089
Train Epoch: 51 [12800/60000 (21%)]	Loss: 0.001529
Train Epoch: 51 [25600/60000 (43%)]	Loss: 0.001155
Train Epoch: 51 [38400/60000 (64%)]	Loss: 0.001385
Train Epoch: 51 [51200/60000 (85%)]	Loss: 0.004367
==> Saving model ...

Test set: Average loss: 0.0417, Accuracy: 9890/10000 (98.90%)
Best Accuracy: 98.90%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 52 [0/60000 (0%)]	Loss: 0.003883
Train Epoch: 52 [12800/60000 (21%)]	Loss: 0.009429
Train Epoch: 52 [25600/60000 (43%)]	Loss: 0.002998
Train Epoch: 52 [38400/60000 (64%)]	Loss: 0.002617
Train Epoch: 52 [51200/60000 (85%)]	Loss: 0.002077
==> Saving model ...

Test set: Average loss: 0.0415, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 53 [0/60000 (0%)]	Loss: 0.002647
Train Epoch: 53 [12800/60000 (21%)]	Loss: 0.000922
Train Epoch: 53 [25600/60000 (43%)]	Loss: 0.001617
Train Epoch: 53 [38400/60000 (64%)]	Loss: 0.001667
Train Epoch: 53 [51200/60000 (85%)]	Loss: 0.003883
==> Saving model ...

Test set: Average loss: 0.0417, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 54 [0/60000 (0%)]	Loss: 0.010712
Train Epoch: 54 [12800/60000 (21%)]	Loss: 0.000547
Train Epoch: 54 [25600/60000 (43%)]	Loss: 0.005152
Train Epoch: 54 [38400/60000 (64%)]	Loss: 0.001358
Train Epoch: 54 [51200/60000 (85%)]	Loss: 0.002461
==> Saving model ...

Test set: Average loss: 0.0416, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 55 [0/60000 (0%)]	Loss: 0.003331
Train Epoch: 55 [12800/60000 (21%)]	Loss: 0.001192
Train Epoch: 55 [25600/60000 (43%)]	Loss: 0.000161
Train Epoch: 55 [38400/60000 (64%)]	Loss: 0.001109
Train Epoch: 55 [51200/60000 (85%)]	Loss: 0.004621
==> Saving model ...

Test set: Average loss: 0.0416, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 56 [0/60000 (0%)]	Loss: 0.003728
Train Epoch: 56 [12800/60000 (21%)]	Loss: 0.001887
Train Epoch: 56 [25600/60000 (43%)]	Loss: 0.002939
Train Epoch: 56 [38400/60000 (64%)]	Loss: 0.001071
Train Epoch: 56 [51200/60000 (85%)]	Loss: 0.000966
==> Saving model ...

Test set: Average loss: 0.0416, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 57 [0/60000 (0%)]	Loss: 0.001797
Train Epoch: 57 [12800/60000 (21%)]	Loss: 0.004041
Train Epoch: 57 [25600/60000 (43%)]	Loss: 0.004290
Train Epoch: 57 [38400/60000 (64%)]	Loss: 0.002463
Train Epoch: 57 [51200/60000 (85%)]	Loss: 0.005322
==> Saving model ...

Test set: Average loss: 0.0416, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 58 [0/60000 (0%)]	Loss: 0.001237
Train Epoch: 58 [12800/60000 (21%)]	Loss: 0.000731
Train Epoch: 58 [25600/60000 (43%)]	Loss: 0.001777
Train Epoch: 58 [38400/60000 (64%)]	Loss: 0.001033
Train Epoch: 58 [51200/60000 (85%)]	Loss: 0.003042
==> Saving model ...

Test set: Average loss: 0.0417, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.00010000000000000002
Train Epoch: 59 [0/60000 (0%)]	Loss: 0.000355
Train Epoch: 59 [12800/60000 (21%)]	Loss: 0.000318
Train Epoch: 59 [25600/60000 (43%)]	Loss: 0.000729
Train Epoch: 59 [38400/60000 (64%)]	Loss: 0.002926
Train Epoch: 59 [51200/60000 (85%)]	Loss: 0.002477
==> Saving model ...

Test set: Average loss: 0.0441, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 1.0000000000000003e-05
Train Epoch: 60 [0/60000 (0%)]	Loss: 0.007559
Train Epoch: 60 [12800/60000 (21%)]	Loss: 0.000615
Train Epoch: 60 [25600/60000 (43%)]	Loss: 0.000477
Train Epoch: 60 [38400/60000 (64%)]	Loss: 0.001647
Train Epoch: 60 [51200/60000 (85%)]	Loss: 0.001723
==> Saving model ...

Test set: Average loss: 0.0416, Accuracy: 9892/10000 (98.92%)
Best Accuracy: 98.92%

------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        170 /        200 (85.0%) weights are pruned
- Layer 1:       2945 /       3200 (92.0%) weights are pruned
- Layer 2:      54954 /      65536 (83.9%) weights are pruned
- Layer 3:       1924 /       2560 (75.2%) weights are pruned
- Total  :      59993 /      71496 (83.9%) weights are pruned
------------------------------------------------------------------


==> Setting params:
batch_size : 128
test_batch_size : 128
epochs : 60
lr_epochs : 20
lr : 0.01
momentum : 0.9
weight_decay : 0.0001
no_cuda : False
seed : 1
log_interval : 100
arch : LeNet_5
pretrained : saved_models/LeNet_5.prune.intermittent.group_size5.4.pth.tar
evaluate : False
retrain : False
prune : intermittent
prune_target : None
stage : 5
group : [1, 1, 1, 5]
penalty : 0.0
pruning_ratio : 0.0
threshold : 0.0
with_sen : False
cuda : False
====================

LeNet_5(
  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv1): ReLU(inplace=True)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu_conv2): ReLU(inplace=True)
  (pool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (ip1): Linear(in_features=256, out_features=256, bias=True)
  (relu_ip1): ReLU(inplace=True)
  (ip2): Linear(in_features=256, out_features=10, bias=True)
)
==> Start pruning ...
pruning_ratios: [0.35, 0.4, 0.3, 0.25]
------------------------------------------------------------------
- Intermittent-aware weight pruning info:
- Layer 0:        180 /        200 (90.0%) weights are pruned
- Layer 1:       3045 /       3200 (95.2%) weights are pruned
- Layer 2:      58243 /      65536 (88.9%) weights are pruned
- Layer 3:       2079 /       2560 (81.2%) weights are pruned
- Total  :      63547 /      71496 (88.9%) weights are pruned
------------------------------------------------------------------

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0711, Accuracy: 9775/10000 (97.75%)
Best Accuracy: 97.75%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0637, Accuracy: 9807/10000 (98.07%)
Best Accuracy: 98.07%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0608, Accuracy: 9812/10000 (98.12%)
Best Accuracy: 98.12%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0611, Accuracy: 9815/10000 (98.15%)
Best Accuracy: 98.15%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0587, Accuracy: 9817/10000 (98.17%)
Best Accuracy: 98.17%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0521, Accuracy: 9845/10000 (98.45%)
Best Accuracy: 98.45%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0567, Accuracy: 9835/10000 (98.35%)
Best Accuracy: 98.35%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0531, Accuracy: 9846/10000 (98.46%)
Best Accuracy: 98.46%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0516, Accuracy: 9849/10000 (98.49%)
Best Accuracy: 98.49%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0543, Accuracy: 9847/10000 (98.47%)
Best Accuracy: 98.47%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0574, Accuracy: 9824/10000 (98.24%)
Best Accuracy: 98.24%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0520, Accuracy: 9844/10000 (98.44%)
Best Accuracy: 98.44%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0549, Accuracy: 9834/10000 (98.34%)
Best Accuracy: 98.34%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0531, Accuracy: 9845/10000 (98.45%)
Best Accuracy: 98.45%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0523, Accuracy: 9847/10000 (98.47%)
Best Accuracy: 98.47%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0540, Accuracy: 9838/10000 (98.38%)
Best Accuracy: 98.38%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0520, Accuracy: 9843/10000 (98.43%)
Best Accuracy: 98.43%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0560, Accuracy: 9843/10000 (98.43%)
Best Accuracy: 98.43%

Learning rate: 0.01
==> Saving model ...

Test set: Average loss: 0.0550, Accuracy: 9853/10000 (98.53%)
Best Accuracy: 98.53%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0502, Accuracy: 9863/10000 (98.63%)
Best Accuracy: 98.63%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0498, Accuracy: 9865/10000 (98.65%)
Best Accuracy: 98.65%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0516, Accuracy: 9863/10000 (98.63%)
Best Accuracy: 98.63%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0614, Accuracy: 9860/10000 (98.60%)
Best Accuracy: 98.60%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0505, Accuracy: 9859/10000 (98.59%)
Best Accuracy: 98.59%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0508, Accuracy: 9855/10000 (98.55%)
Best Accuracy: 98.55%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0500, Accuracy: 9861/10000 (98.61%)
Best Accuracy: 98.61%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0501, Accuracy: 9861/10000 (98.61%)
Best Accuracy: 98.61%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0504, Accuracy: 9860/10000 (98.60%)
Best Accuracy: 98.60%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0503, Accuracy: 9860/10000 (98.60%)
Best Accuracy: 98.60%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0530, Accuracy: 9859/10000 (98.59%)
Best Accuracy: 98.59%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0506, Accuracy: 9857/10000 (98.57%)
Best Accuracy: 98.57%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0505, Accuracy: 9860/10000 (98.60%)
Best Accuracy: 98.60%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0503, Accuracy: 9860/10000 (98.60%)
Best Accuracy: 98.60%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0538, Accuracy: 9858/10000 (98.58%)
Best Accuracy: 98.58%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0508, Accuracy: 9858/10000 (98.58%)
Best Accuracy: 98.58%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0508, Accuracy: 9861/10000 (98.61%)
Best Accuracy: 98.61%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0508, Accuracy: 9858/10000 (98.58%)
Best Accuracy: 98.58%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0503, Accuracy: 9863/10000 (98.63%)
Best Accuracy: 98.63%

Learning rate: 0.001
==> Saving model ...

Test set: Average loss: 0.0512, Accuracy: 9861/10000 (98.61%)
Best Accuracy: 98.61%

Learning rate: 0.00010000000000000002
==> Saving model ...

Test set: Average loss: 0.0511, Accuracy: 9860/10000 (98.60%)
Best Accuracy: 98.60%

Learning rate: 0.00010000000000000002
==> Saving model ...

Test set: Average loss: 0.0508, Accuracy: 9861/10000 (98.61%)
Best Accuracy: 98.61%

Learning rate: 0.00010000000000000002
==> Saving model ...

Test set: Average loss: 0.0507, Accuracy: 9861/10000 (98.61%)
Best Accuracy: 98.61%

Learning rate: 0.00010000000000000002
==> Saving model ...

Test set: Average loss: 0.0506, Accuracy: 9861/10000 (98.61%)
Best Accuracy: 98.61%

Learning rate: 0.00010000000000000002
==> Saving model ...

Test set: Average loss: 0.0506, Accuracy: 9861/10000 (98.61%)
Best Accuracy: 98.61%

Learning rate: 0.00010000000000000002
==> Saving model ...

Test set: Average loss: 0.0506, Accuracy: 9861/10000 (98.61%)
Best Accuracy: 98.61%

Learning rate: 0.00010000000000000002
