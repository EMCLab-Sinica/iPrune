
==> Dump Arguments:
pruning method: 
visible gpus: 4
sensitivity analysis: OFF
overall pruning ratio: 0.2
stage: 

0
0

==> Setting params:
batch_size : 16
test_batch_size : 16
epochs : 150
lr_epochs : 50
lr : 0.0005
momentum : 0.9
weight_decay : 0.0001
no_cuda : False
seed : 1
log_interval : 100
arch : KWS_CNN_S
pretrained : None
evaluate : False
retrain : False
prune : None
prune_shape : vector
prune_target : None
stage : 0
debug : -1
candidates_pruning_ratios : [0, 0, 0, 0, 0]
gpus : [0]
visible_gpus : 4
learning_rate_list : [0.0005, 0.0001, 2e-05]
sa : False
sen_ana : False
overall_pruning_ratio : 0.2
cuda : False
====================

Load cached data ...
Load cached data ...
Load cached data ...
KWS_CNN_S(
  (conv1): Conv2d(1, 28, kernel_size=(10, 4), stride=(1, 1))
  (bn1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(28, 28, kernel_size=(10, 4), stride=(2, 1))
  (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ip1): Linear(in_features=1792, out_features=16, bias=True)
  (ip2): Linear(in_features=16, out_features=128, bias=True)
  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ip3): Linear(in_features=128, out_features=12, bias=True)
  (relu): ReLU(inplace=True)
)
[Epoch: 1| Loss: 0.6017| Accuracy: 79.96| Best Accuracy: 79.96]
[Epoch: 2| Loss: 0.5164| Accuracy: 82.76| Best Accuracy: 82.76]
[Epoch: 3| Loss: 0.4850| Accuracy: 84.19| Best Accuracy: 84.19]
[Epoch: 4| Loss: 0.4378| Accuracy: 85.50| Best Accuracy: 85.50]
[Epoch: 5| Loss: 0.4215| Accuracy: 86.73| Best Accuracy: 86.73]
[Epoch: 6| Loss: 0.4069| Accuracy: 86.69| Best Accuracy: 86.73]
[Epoch: 7| Loss: 0.4395| Accuracy: 85.60| Best Accuracy: 86.73]
[Epoch: 8| Loss: 0.4056| Accuracy: 87.20| Best Accuracy: 87.20]
[Epoch: 9| Loss: 0.4034| Accuracy: 86.93| Best Accuracy: 87.20]
[Epoch: 10| Loss: 0.4153| Accuracy: 86.28| Best Accuracy: 87.20]
[Epoch: 11| Loss: 0.4229| Accuracy: 86.26| Best Accuracy: 87.20]
[Epoch: 12| Loss: 0.3838| Accuracy: 87.65| Best Accuracy: 87.65]
[Epoch: 13| Loss: 0.3808| Accuracy: 87.85| Best Accuracy: 87.85]
[Epoch: 14| Loss: 0.4124| Accuracy: 87.22| Best Accuracy: 87.85]
[Epoch: 15| Loss: 0.4291| Accuracy: 87.34| Best Accuracy: 87.85]
[Epoch: 16| Loss: 0.4284| Accuracy: 86.46| Best Accuracy: 87.85]
[Epoch: 17| Loss: 0.4119| Accuracy: 87.38| Best Accuracy: 87.85]
[Epoch: 18| Loss: 0.4218| Accuracy: 86.99| Best Accuracy: 87.85]
[Epoch: 19| Loss: 0.4173| Accuracy: 87.20| Best Accuracy: 87.85]
[Epoch: 20| Loss: 0.4279| Accuracy: 87.20| Best Accuracy: 87.85]
[Epoch: 21| Loss: 0.4578| Accuracy: 86.97| Best Accuracy: 87.85]
[Epoch: 22| Loss: 0.4688| Accuracy: 86.22| Best Accuracy: 87.85]
[Epoch: 23| Loss: 0.4642| Accuracy: 86.20| Best Accuracy: 87.85]
[Epoch: 24| Loss: 0.4770| Accuracy: 86.56| Best Accuracy: 87.85]
[Epoch: 25| Loss: 0.4438| Accuracy: 87.26| Best Accuracy: 87.85]
[Epoch: 26| Loss: 0.5150| Accuracy: 85.81| Best Accuracy: 87.85]
[Epoch: 27| Loss: 0.4826| Accuracy: 86.87| Best Accuracy: 87.85]
[Epoch: 28| Loss: 0.4747| Accuracy: 86.38| Best Accuracy: 87.85]
[Epoch: 29| Loss: 0.4686| Accuracy: 86.52| Best Accuracy: 87.85]
[Epoch: 30| Loss: 0.4991| Accuracy: 86.20| Best Accuracy: 87.85]
[Epoch: 31| Loss: 0.5139| Accuracy: 86.11| Best Accuracy: 87.85]
[Epoch: 32| Loss: 0.5429| Accuracy: 85.79| Best Accuracy: 87.85]
[Epoch: 33| Loss: 0.5470| Accuracy: 85.56| Best Accuracy: 87.85]
[Epoch: 34| Loss: 0.5326| Accuracy: 85.91| Best Accuracy: 87.85]
[Epoch: 35| Loss: 0.5422| Accuracy: 86.03| Best Accuracy: 87.85]
[Epoch: 36| Loss: 0.5364| Accuracy: 85.77| Best Accuracy: 87.85]
[Epoch: 37| Loss: 0.5333| Accuracy: 85.60| Best Accuracy: 87.85]
[Epoch: 38| Loss: 0.5292| Accuracy: 85.81| Best Accuracy: 87.85]
[Epoch: 39| Loss: 0.5454| Accuracy: 85.42| Best Accuracy: 87.85]
[Epoch: 40| Loss: 0.5239| Accuracy: 86.44| Best Accuracy: 87.85]
[Epoch: 41| Loss: 0.5389| Accuracy: 85.95| Best Accuracy: 87.85]
[Epoch: 42| Loss: 0.5240| Accuracy: 86.38| Best Accuracy: 87.85]
[Epoch: 43| Loss: 0.5648| Accuracy: 85.15| Best Accuracy: 87.85]
[Epoch: 44| Loss: 0.5562| Accuracy: 86.05| Best Accuracy: 87.85]
[Epoch: 45| Loss: 0.5734| Accuracy: 86.11| Best Accuracy: 87.85]
[Epoch: 46| Loss: 0.5767| Accuracy: 85.79| Best Accuracy: 87.85]
[Epoch: 47| Loss: 0.5901| Accuracy: 85.73| Best Accuracy: 87.85]
[Epoch: 48| Loss: 0.5657| Accuracy: 85.56| Best Accuracy: 87.85]
[Epoch: 49| Loss: 0.5884| Accuracy: 85.48| Best Accuracy: 87.85]
adjusting learning rate to 0.0005 ...
[Epoch: 50| Loss: 0.5330| Accuracy: 86.69| Best Accuracy: 87.85]
[Epoch: 51| Loss: 0.5892| Accuracy: 85.58| Best Accuracy: 87.85]
[Epoch: 52| Loss: 0.5670| Accuracy: 86.07| Best Accuracy: 87.85]
[Epoch: 53| Loss: 0.5646| Accuracy: 85.87| Best Accuracy: 87.85]
[Epoch: 54| Loss: 0.5746| Accuracy: 85.91| Best Accuracy: 87.85]
[Epoch: 55| Loss: 0.6230| Accuracy: 84.79| Best Accuracy: 87.85]
[Epoch: 56| Loss: 0.5832| Accuracy: 85.73| Best Accuracy: 87.85]
[Epoch: 57| Loss: 0.5744| Accuracy: 86.11| Best Accuracy: 87.85]
[Epoch: 58| Loss: 0.6129| Accuracy: 85.09| Best Accuracy: 87.85]
[Epoch: 59| Loss: 0.5935| Accuracy: 85.48| Best Accuracy: 87.85]
[Epoch: 60| Loss: 0.6016| Accuracy: 84.83| Best Accuracy: 87.85]
[Epoch: 61| Loss: 0.5706| Accuracy: 85.87| Best Accuracy: 87.85]
[Epoch: 62| Loss: 0.5816| Accuracy: 85.91| Best Accuracy: 87.85]
[Epoch: 63| Loss: 0.6031| Accuracy: 85.81| Best Accuracy: 87.85]
[Epoch: 64| Loss: 0.5879| Accuracy: 85.58| Best Accuracy: 87.85]
[Epoch: 65| Loss: 0.6196| Accuracy: 85.93| Best Accuracy: 87.85]
[Epoch: 66| Loss: 0.5925| Accuracy: 86.03| Best Accuracy: 87.85]
[Epoch: 67| Loss: 0.5951| Accuracy: 85.83| Best Accuracy: 87.85]
[Epoch: 68| Loss: 0.5740| Accuracy: 85.95| Best Accuracy: 87.85]
[Epoch: 69| Loss: 0.6249| Accuracy: 84.93| Best Accuracy: 87.85]
[Epoch: 70| Loss: 0.6266| Accuracy: 85.30| Best Accuracy: 87.85]
[Epoch: 71| Loss: 0.6718| Accuracy: 84.74| Best Accuracy: 87.85]
[Epoch: 72| Loss: 0.5722| Accuracy: 85.89| Best Accuracy: 87.85]
[Epoch: 73| Loss: 0.5963| Accuracy: 85.89| Best Accuracy: 87.85]
[Epoch: 74| Loss: 0.6235| Accuracy: 85.81| Best Accuracy: 87.85]
[Epoch: 75| Loss: 0.5824| Accuracy: 85.52| Best Accuracy: 87.85]
[Epoch: 76| Loss: 0.6356| Accuracy: 85.34| Best Accuracy: 87.85]
[Epoch: 77| Loss: 0.6361| Accuracy: 85.40| Best Accuracy: 87.85]
[Epoch: 78| Loss: 0.6159| Accuracy: 85.81| Best Accuracy: 87.85]
[Epoch: 79| Loss: 0.6265| Accuracy: 85.83| Best Accuracy: 87.85]
[Epoch: 80| Loss: 0.6224| Accuracy: 85.56| Best Accuracy: 87.85]
[Epoch: 81| Loss: 0.6306| Accuracy: 85.36| Best Accuracy: 87.85]
[Epoch: 82| Loss: 0.6382| Accuracy: 85.03| Best Accuracy: 87.85]
[Epoch: 83| Loss: 0.5764| Accuracy: 86.48| Best Accuracy: 87.85]
[Epoch: 84| Loss: 0.6579| Accuracy: 84.91| Best Accuracy: 87.85]
[Epoch: 85| Loss: 0.6653| Accuracy: 84.36| Best Accuracy: 87.85]
[Epoch: 86| Loss: 0.6507| Accuracy: 85.58| Best Accuracy: 87.85]
[Epoch: 87| Loss: 0.5967| Accuracy: 86.36| Best Accuracy: 87.85]
[Epoch: 88| Loss: 0.6807| Accuracy: 84.56| Best Accuracy: 87.85]
[Epoch: 89| Loss: 0.5999| Accuracy: 86.22| Best Accuracy: 87.85]
[Epoch: 90| Loss: 0.6335| Accuracy: 85.77| Best Accuracy: 87.85]
[Epoch: 91| Loss: 0.6199| Accuracy: 85.87| Best Accuracy: 87.85]
[Epoch: 92| Loss: 0.6366| Accuracy: 85.36| Best Accuracy: 87.85]
[Epoch: 93| Loss: 0.6545| Accuracy: 85.36| Best Accuracy: 87.85]
[Epoch: 94| Loss: 0.6618| Accuracy: 85.69| Best Accuracy: 87.85]
[Epoch: 95| Loss: 0.6000| Accuracy: 86.05| Best Accuracy: 87.85]
[Epoch: 96| Loss: 0.6369| Accuracy: 85.50| Best Accuracy: 87.85]
[Epoch: 97| Loss: 0.6244| Accuracy: 85.85| Best Accuracy: 87.85]
[Epoch: 98| Loss: 0.6143| Accuracy: 85.56| Best Accuracy: 87.85]
[Epoch: 99| Loss: 0.6101| Accuracy: 86.24| Best Accuracy: 87.85]
adjusting learning rate to 0.0001 ...
[Epoch: 100| Loss: 0.5849| Accuracy: 86.71| Best Accuracy: 87.85]
[Epoch: 101| Loss: 0.6084| Accuracy: 86.63| Best Accuracy: 87.85]
[Epoch: 102| Loss: 0.6291| Accuracy: 86.38| Best Accuracy: 87.85]
[Epoch: 103| Loss: 0.6132| Accuracy: 86.91| Best Accuracy: 87.85]
[Epoch: 104| Loss: 0.6474| Accuracy: 86.09| Best Accuracy: 87.85]
[Epoch: 105| Loss: 0.6249| Accuracy: 86.50| Best Accuracy: 87.85]
[Epoch: 106| Loss: 0.6554| Accuracy: 86.52| Best Accuracy: 87.85]
[Epoch: 107| Loss: 0.6442| Accuracy: 86.16| Best Accuracy: 87.85]
[Epoch: 108| Loss: 0.6649| Accuracy: 85.87| Best Accuracy: 87.85]
[Epoch: 109| Loss: 0.6549| Accuracy: 86.20| Best Accuracy: 87.85]
[Epoch: 110| Loss: 0.6631| Accuracy: 86.56| Best Accuracy: 87.85]
[Epoch: 111| Loss: 0.6334| Accuracy: 86.28| Best Accuracy: 87.85]
[Epoch: 112| Loss: 0.6668| Accuracy: 86.20| Best Accuracy: 87.85]
[Epoch: 113| Loss: 0.6487| Accuracy: 86.42| Best Accuracy: 87.85]
[Epoch: 114| Loss: 0.6891| Accuracy: 86.24| Best Accuracy: 87.85]
[Epoch: 115| Loss: 0.6685| Accuracy: 86.42| Best Accuracy: 87.85]
[Epoch: 116| Loss: 0.6937| Accuracy: 85.71| Best Accuracy: 87.85]
[Epoch: 117| Loss: 0.6982| Accuracy: 85.83| Best Accuracy: 87.85]
[Epoch: 118| Loss: 0.6819| Accuracy: 85.81| Best Accuracy: 87.85]
[Epoch: 119| Loss: 0.7038| Accuracy: 85.38| Best Accuracy: 87.85]
[Epoch: 120| Loss: 0.7060| Accuracy: 85.99| Best Accuracy: 87.85]
[Epoch: 121| Loss: 0.6814| Accuracy: 86.36| Best Accuracy: 87.85]
[Epoch: 122| Loss: 0.6887| Accuracy: 85.75| Best Accuracy: 87.85]
[Epoch: 123| Loss: 0.7171| Accuracy: 86.05| Best Accuracy: 87.85]
[Epoch: 124| Loss: 0.6853| Accuracy: 86.05| Best Accuracy: 87.85]
[Epoch: 125| Loss: 0.6980| Accuracy: 86.03| Best Accuracy: 87.85]
[Epoch: 126| Loss: 0.6932| Accuracy: 85.85| Best Accuracy: 87.85]
[Epoch: 127| Loss: 0.6998| Accuracy: 86.11| Best Accuracy: 87.85]
[Epoch: 128| Loss: 0.7031| Accuracy: 85.85| Best Accuracy: 87.85]
[Epoch: 129| Loss: 0.7039| Accuracy: 85.99| Best Accuracy: 87.85]
[Epoch: 130| Loss: 0.7238| Accuracy: 85.85| Best Accuracy: 87.85]
[Epoch: 131| Loss: 0.6943| Accuracy: 86.22| Best Accuracy: 87.85]
[Epoch: 132| Loss: 0.7044| Accuracy: 85.32| Best Accuracy: 87.85]
[Epoch: 133| Loss: 0.7312| Accuracy: 86.20| Best Accuracy: 87.85]
[Epoch: 134| Loss: 0.7364| Accuracy: 85.79| Best Accuracy: 87.85]
[Epoch: 135| Loss: 0.7129| Accuracy: 85.83| Best Accuracy: 87.85]
[Epoch: 136| Loss: 0.7141| Accuracy: 86.09| Best Accuracy: 87.85]
[Epoch: 137| Loss: 0.7155| Accuracy: 85.66| Best Accuracy: 87.85]
[Epoch: 138| Loss: 0.7048| Accuracy: 85.73| Best Accuracy: 87.85]
[Epoch: 139| Loss: 0.7287| Accuracy: 85.40| Best Accuracy: 87.85]
[Epoch: 140| Loss: 0.7194| Accuracy: 85.81| Best Accuracy: 87.85]
[Epoch: 141| Loss: 0.7186| Accuracy: 86.01| Best Accuracy: 87.85]
[Epoch: 142| Loss: 0.7320| Accuracy: 85.95| Best Accuracy: 87.85]
[Epoch: 143| Loss: 0.7189| Accuracy: 85.58| Best Accuracy: 87.85]
[Epoch: 144| Loss: 0.7288| Accuracy: 85.81| Best Accuracy: 87.85]
[Epoch: 145| Loss: 0.7348| Accuracy: 85.87| Best Accuracy: 87.85]
[Epoch: 146| Loss: 0.7309| Accuracy: 85.83| Best Accuracy: 87.85]
[Epoch: 147| Loss: 0.7250| Accuracy: 85.60| Best Accuracy: 87.85]
[Epoch: 148| Loss: 0.7298| Accuracy: 85.38| Best Accuracy: 87.85]
[Epoch: 149| Loss: 0.7034| Accuracy: 85.62| Best Accuracy: 87.85]
adjusting learning rate to 2e-05 ...
[Epoch: 150| Loss: 0.7236| Accuracy: 85.91| Best Accuracy: 87.85]
